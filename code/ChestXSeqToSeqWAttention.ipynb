{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1210 10:34:36.688496 139976365537024 __init__.py:321] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "W1210 10:34:36.916290 139976365537024 __init__.py:321] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "W1210 10:34:37.087058 139976365537024 __init__.py:352] Limited tf.summary API due to missing TensorBoard installation.\n",
      "W1210 10:34:37.731662 139976365537024 __init__.py:321] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "# sys.path.append(\"..\")\n",
    "from utils import data_proc_tools as dpt\n",
    "from utils import plot_tools as pt\n",
    "from utils.custom_metrics import recall, precision, binary_accuracy\n",
    "from utils.custom_metrics import recall_np, precision_np, binary_accuracy_np, multilabel_confusion_matrix\n",
    "from utils.rnn_textsum_models import Seq2SeqAtt\n",
    "import random\n",
    "random.seed(42)\n",
    "random_state=1000\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import pylab\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dir = '/vol/medic02/users/ag6516/radiology_report_summarisation/'\n",
    "data_dir = dir + 'data/'\n",
    "\n",
    "aug = 'aug'\n",
    "\n",
    "model_output_dir = dir + 'trained_models/att_seq2seq/'\n",
    "\n",
    "train_df = pd.read_pickle(data_dir + 'train/{}_train.pkl'.format(aug))\n",
    "val_df = pd.read_pickle(data_dir + 'val/val.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare sequence data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>examid</th>\n",
       "      <th>report</th>\n",
       "      <th>all_mesh</th>\n",
       "      <th>single_mesh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR1000_IM-0003</td>\n",
       "      <td>[increased, opacity, within, right, upper, lobe, possible, mass, associated, area, atelectasis, focal, consolidation, ., cardiac, silhouette, within, normal, limits, ., opacity, left, midlung, overlying, posterior, left, 5th, rib, may, represent, focal, airspace, disease, ., increased, opacity, right, upper, lobe, associated, atelectasis, may, represent, focal, consolidation, mass, lesion, atelectasis, ., recommend, chest, ct, evaluation, ., opacity, overlying, left, 5th, rib, may, represent, focal, airspace, disease]</td>\n",
       "      <td>[opacity, lung, lingula, opacity, lung, upper_lobe, right, pulmonary_atelectasis, upper_lobe, right]</td>\n",
       "      <td>[opacity, lung, upper_lobe, right]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR1001_IM-0004</td>\n",
       "      <td>[interstitial, markings, diffusely, prominent, throughout, lungs, ., heart, size, normal, ., pulmonary, normal, ., diffuse, fibrosis]</td>\n",
       "      <td>[diffuse, markings, lung, bilateral, interstitial, diffuse, prominent]</td>\n",
       "      <td>[markings, lung, bilateral, interstitial, diffuse, prominent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR1002_IM-0004</td>\n",
       "      <td>[status, post, left, mastectomy, ., heart, size, normal, ., lungs, clear]</td>\n",
       "      <td>[left]</td>\n",
       "      <td>[left]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR1003_IM-0005</td>\n",
       "      <td>[heart, size, pulmonary, vascularity, appear, within, normal, limits, ., retrocardiac, soft, tissue, density, present, ., appears, air, within, suggest, represents, hiatal, hernia, ., vascular, calcification, noted, ., calcified, granuloma, seen, ., interval, development, bandlike, opacity, left, lung, base, ., may, represent, atelectasis, ., osteopenia, present, spine, ., retrocardiac, soft, tissue, density, ., appearance, suggests, hiatal, hernia, ., left, base, bandlike, opacity, ., appearance, suggests, atelectasis]</td>\n",
       "      <td>[bone_diseases_metabolic, spine, calcified_granuloma, calcinosis, blood_vessels, density, retrocardiac, opacity, lung, base, left]</td>\n",
       "      <td>[opacity, lung, base, left]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR1004_IM-0005</td>\n",
       "      <td>[heart, ,, pulmonary, mediastinum, within, normal, limits, ., aorta, tortuous, ectatic, ., degenerative, changes, acromioclavicular, joints, ., degenerative, changes, spine, ., ivc, identified]</td>\n",
       "      <td>[aorta, tortuous, catheters_indwelling, shoulder, bilateral, degenerative, spine, degenerative]</td>\n",
       "      <td>[shoulder, bilateral, degenerative]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            examid  \\\n",
       "0  CXR1000_IM-0003   \n",
       "1  CXR1001_IM-0004   \n",
       "2  CXR1002_IM-0004   \n",
       "3  CXR1003_IM-0005   \n",
       "4  CXR1004_IM-0005   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          report  \\\n",
       "0  [increased, opacity, within, right, upper, lobe, possible, mass, associated, area, atelectasis, focal, consolidation, ., cardiac, silhouette, within, normal, limits, ., opacity, left, midlung, overlying, posterior, left, 5th, rib, may, represent, focal, airspace, disease, ., increased, opacity, right, upper, lobe, associated, atelectasis, may, represent, focal, consolidation, mass, lesion, atelectasis, ., recommend, chest, ct, evaluation, ., opacity, overlying, left, 5th, rib, may, represent, focal, airspace, disease]     \n",
       "1  [interstitial, markings, diffusely, prominent, throughout, lungs, ., heart, size, normal, ., pulmonary, normal, ., diffuse, fibrosis]                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "2  [status, post, left, mastectomy, ., heart, size, normal, ., lungs, clear]                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "3  [heart, size, pulmonary, vascularity, appear, within, normal, limits, ., retrocardiac, soft, tissue, density, present, ., appears, air, within, suggest, represents, hiatal, hernia, ., vascular, calcification, noted, ., calcified, granuloma, seen, ., interval, development, bandlike, opacity, left, lung, base, ., may, represent, atelectasis, ., osteopenia, present, spine, ., retrocardiac, soft, tissue, density, ., appearance, suggests, hiatal, hernia, ., left, base, bandlike, opacity, ., appearance, suggests, atelectasis]   \n",
       "4  [heart, ,, pulmonary, mediastinum, within, normal, limits, ., aorta, tortuous, ectatic, ., degenerative, changes, acromioclavicular, joints, ., degenerative, changes, spine, ., ivc, identified]                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "                                                                                                                             all_mesh  \\\n",
       "0  [opacity, lung, lingula, opacity, lung, upper_lobe, right, pulmonary_atelectasis, upper_lobe, right]                                 \n",
       "1  [diffuse, markings, lung, bilateral, interstitial, diffuse, prominent]                                                               \n",
       "2  [left]                                                                                                                               \n",
       "3  [bone_diseases_metabolic, spine, calcified_granuloma, calcinosis, blood_vessels, density, retrocardiac, opacity, lung, base, left]   \n",
       "4  [aorta, tortuous, catheters_indwelling, shoulder, bilateral, degenerative, spine, degenerative]                                      \n",
       "\n",
       "                                                     single_mesh  \n",
       "0  [opacity, lung, upper_lobe, right]                             \n",
       "1  [markings, lung, bilateral, interstitial, diffuse, prominent]  \n",
       "2  [left]                                                         \n",
       "3  [opacity, lung, base, left]                                    \n",
       "4  [shoulder, bilateral, degenerative]                            "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepend and append start and end tokens to mesh captions and text reports\n",
    "start_token = 'start'\n",
    "end_token = 'end'\n",
    "unknown_token = '**unknown**'\n",
    "max_mesh_length = 13 # avg. + 1std. + start + end\n",
    "max_report_length = 37 # avg. + 1std. + start + end\n",
    "\n",
    "train_df['pad_mesh_caption'] = train_df.all_mesh.apply(lambda x: dpt.pad_sequence(x, max_mesh_length, start_token, end_token))\n",
    "train_df['pad_text_report'] = train_df.report.apply(lambda x: dpt.pad_sequence(x, max_report_length, start_token, end_token))\n",
    "\n",
    "val_df['pad_mesh_caption'] = val_df.all_mesh.apply(lambda x: dpt.pad_sequence(x, max_mesh_length, start_token, end_token))\n",
    "val_df['pad_text_report'] = val_df.report.apply(lambda x: dpt.pad_sequence(x, max_report_length, start_token, end_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorise text reports and mesh captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mesh = list(train_df.pad_mesh_caption)\n",
    "train_reports = list(train_df.pad_text_report)\n",
    "\n",
    "# vectorize mesh captions\n",
    "dpt.mesh_to_vectors(train_mesh, dicts_dir=data_dir+'dicts/', load_dicts=True, save=True, output_dir=data_dir+'train/')\n",
    "\n",
    "# vectorise reports\n",
    "dpt.reports_to_vectors(train_reports, dicts_dir=data_dir+'dicts/', load_dicts=True, save=True, output_dir=data_dir+'train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_reports = list(val_df.pad_text_report)\n",
    "val_mesh = list(val_df.pad_mesh_caption)\n",
    "\n",
    "# vectorise val reports + mesh using the same dict as created for train\n",
    "dpt.mesh_to_vectors(val_mesh, dicts_dir=data_dir+'dicts/', load_dicts=True, save=True, output_dir=data_dir+'val/')\n",
    "dpt.reports_to_vectors(val_reports, dicts_dir=data_dir+'dicts/', load_dicts=True, save=True, output_dir=data_dir+'val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, id_to_word = dpt.load_report_dicts(data_dir+'dicts/')\n",
    "mesh_to_id, id_to_mesh = dpt.load_mesh_dicts(data_dir+'dicts/')\n",
    "\n",
    "report_vocab_length = len(word_to_id)\n",
    "mesh_vocab_length = len(mesh_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1475, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_vocab_length, mesh_vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays of indixes for input sentences, output entities and shifted output entities (t-1)\n",
    "train_token_ids_array = np.load(data_dir + 'train/token_ids_array.npy')\n",
    "train_mesh_ids_array = np.load(data_dir + 'train/mesh_ids_array.npy')\n",
    "train_mesh_ids_array_shifted =[np.concatenate((mesh_to_id[start_token], t[:-1]), axis=None) for t in train_mesh_ids_array]\n",
    "train_mesh_ids_array_shifted = np.asarray(train_mesh_ids_array_shifted)\n",
    "\n",
    "val_token_ids_array = np.load(data_dir + 'val/token_ids_array.npy')\n",
    "val_mesh_ids_array = np.load(data_dir + 'val/mesh_ids_array.npy')\n",
    "val_mesh_ids_array_shifted = [np.concatenate((mesh_to_id[start_token], t[:-1]), axis=None) for t in val_mesh_ids_array]\n",
    "val_mesh_ids_array_shifted = np.asarray(val_mesh_ids_array_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encode\n",
    "one_hot_reports_train = dpt.one_hot_sequence(train_token_ids_array, report_vocab_length)\n",
    "one_hot_mesh_train = dpt.one_hot_sequence(train_mesh_ids_array, mesh_vocab_length)\n",
    "one_hot_mesh_shifted_train = dpt.one_hot_sequence(train_mesh_ids_array_shifted, mesh_vocab_length)\n",
    "\n",
    "one_hot_reports_val = dpt.one_hot_sequence(val_token_ids_array, report_vocab_length)\n",
    "one_hot_mesh_val = dpt.one_hot_sequence(val_mesh_ids_array, mesh_vocab_length)\n",
    "one_hot_mesh_shifted_val = dpt.one_hot_sequence(val_mesh_ids_array_shifted, mesh_vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5148, 37, 1475), (5148, 13, 128), (5148, 13, 128))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_reports_train.shape, one_hot_mesh_train.shape, one_hot_mesh_shifted_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Seq-to-Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(128, 37, 1475)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(128, 13, 128)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     multiple             4071424     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   multiple             1312768     input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer multiple             524800      lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (128, 13, 1024)      0           lstm_1[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (128, 13, 128)       131200      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,040,192\n",
      "Trainable params: 6,040,192\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(word_to_id)\n",
    "output_dim = len(mesh_to_id)\n",
    "hidden_dim = 512\n",
    "encoder_emb_dim = 512\n",
    "input_seq_length = max_report_length\n",
    "output_seq_length = max_mesh_length\n",
    "epochs = 100\n",
    "optimizer = 'adam'\n",
    "loss='categorical_crossentropy'\n",
    "batch_size = 128\n",
    "\n",
    "new_experiment = Seq2SeqAtt(epochs=epochs,\n",
    "                               metrics=['accuracy', binary_accuracy,recall,precision],\n",
    "                               optimizer=optimizer,\n",
    "                               loss=loss,\n",
    "                               batch_size=batch_size, \n",
    "                               input_dim=input_dim,\n",
    "                               output_dim=output_dim,\n",
    "                               hidden_dim=hidden_dim,\n",
    "                               input_seq_length=input_seq_length,\n",
    "                               output_seq_length=output_seq_length,\n",
    "                               verbose=True)\n",
    "new_experiment.build_model()\n",
    "new_experiment.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batch generators\n",
    "# train_batch_generator = dpt.batch_generator_seq2seq(train_token_ids_array, report_vocab_length, train_mesh_ids_array, \n",
    "#                                                    train_mesh_ids_array_shifted, mesh_vocab_length, batch_size)\n",
    "\n",
    "# val_batch_generator = dpt.batch_generator_seq2seq(val_token_ids_array, report_vocab_length, val_mesh_ids_array, \n",
    "#                                                    val_mesh_ids_array_shifted, mesh_vocab_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      "5148/5148 [==============================] - 57s 11ms/sample - loss: 2.5337 - accuracy: 0.5581 - binary_accuracy: 0.9944 - recall: 0.4292 - precision: 0.6965 - val_loss: 1.6994 - val_accuracy: 0.6867 - val_binary_accuracy: 0.9961 - val_recall: 0.5672 - val_precision: 0.9137\n",
      "Epoch 2/100\n",
      "5148/5148 [==============================] - 52s 10ms/sample - loss: 1.8231 - accuracy: 0.6285 - binary_accuracy: 0.9959 - recall: 0.5382 - precision: 0.8970 - val_loss: 1.4274 - val_accuracy: 0.6972 - val_binary_accuracy: 0.9968 - val_recall: 0.6443 - val_precision: 0.9302\n",
      "Epoch 3/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 1.6517 - accuracy: 0.6458 - binary_accuracy: 0.9962 - recall: 0.5586 - precision: 0.9304 - val_loss: 1.3168 - val_accuracy: 0.7141 - val_binary_accuracy: 0.9970 - val_recall: 0.6441 - val_precision: 0.9518\n",
      "Epoch 4/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 1.4896 - accuracy: 0.6660 - binary_accuracy: 0.9965 - recall: 0.5796 - precision: 0.9548 - val_loss: 1.1860 - val_accuracy: 0.7282 - val_binary_accuracy: 0.9972 - val_recall: 0.6688 - val_precision: 0.9602\n",
      "Epoch 5/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 1.3208 - accuracy: 0.6952 - binary_accuracy: 0.9967 - recall: 0.5987 - precision: 0.9617 - val_loss: 1.0772 - val_accuracy: 0.7474 - val_binary_accuracy: 0.9972 - val_recall: 0.6880 - val_precision: 0.9374\n",
      "Epoch 6/100\n",
      "5148/5148 [==============================] - 52s 10ms/sample - loss: 1.1536 - accuracy: 0.7245 - binary_accuracy: 0.9969 - recall: 0.6255 - precision: 0.9618 - val_loss: 0.9566 - val_accuracy: 0.7777 - val_binary_accuracy: 0.9974 - val_recall: 0.6906 - val_precision: 0.9780\n",
      "Epoch 7/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 1.0240 - accuracy: 0.7486 - binary_accuracy: 0.9970 - recall: 0.6457 - precision: 0.9581 - val_loss: 0.8704 - val_accuracy: 0.7879 - val_binary_accuracy: 0.9975 - val_recall: 0.7113 - val_precision: 0.9618\n",
      "Epoch 8/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.9233 - accuracy: 0.7638 - binary_accuracy: 0.9972 - recall: 0.6695 - precision: 0.9513 - val_loss: 0.8087 - val_accuracy: 0.7990 - val_binary_accuracy: 0.9976 - val_recall: 0.7375 - val_precision: 0.9451\n",
      "Epoch 9/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.8418 - accuracy: 0.7786 - binary_accuracy: 0.9973 - recall: 0.6916 - precision: 0.9458 - val_loss: 0.7824 - val_accuracy: 0.8079 - val_binary_accuracy: 0.9976 - val_recall: 0.7453 - val_precision: 0.9408\n",
      "Epoch 10/100\n",
      "5148/5148 [==============================] - 52s 10ms/sample - loss: 0.7695 - accuracy: 0.7952 - binary_accuracy: 0.9974 - recall: 0.7126 - precision: 0.9425 - val_loss: 0.7736 - val_accuracy: 0.8092 - val_binary_accuracy: 0.9977 - val_recall: 0.7511 - val_precision: 0.9441\n",
      "Epoch 11/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.7110 - accuracy: 0.8083 - binary_accuracy: 0.9975 - recall: 0.7300 - precision: 0.9444 - val_loss: 0.7353 - val_accuracy: 0.8136 - val_binary_accuracy: 0.9978 - val_recall: 0.7631 - val_precision: 0.9402\n",
      "Epoch 12/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.6577 - accuracy: 0.8196 - binary_accuracy: 0.9976 - recall: 0.7448 - precision: 0.9418 - val_loss: 0.7208 - val_accuracy: 0.8195 - val_binary_accuracy: 0.9978 - val_recall: 0.7706 - val_precision: 0.9386\n",
      "Epoch 13/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.6043 - accuracy: 0.8327 - binary_accuracy: 0.9978 - recall: 0.7602 - precision: 0.9421 - val_loss: 0.6812 - val_accuracy: 0.8318 - val_binary_accuracy: 0.9978 - val_recall: 0.7724 - val_precision: 0.9434\n",
      "Epoch 14/100\n",
      "5148/5148 [==============================] - 52s 10ms/sample - loss: 0.5425 - accuracy: 0.8474 - binary_accuracy: 0.9979 - recall: 0.7804 - precision: 0.9460 - val_loss: 0.6721 - val_accuracy: 0.8331 - val_binary_accuracy: 0.9979 - val_recall: 0.7853 - val_precision: 0.9337\n",
      "Epoch 15/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.4979 - accuracy: 0.8598 - binary_accuracy: 0.9981 - recall: 0.7965 - precision: 0.9483 - val_loss: 0.6938 - val_accuracy: 0.8403 - val_binary_accuracy: 0.9979 - val_recall: 0.8000 - val_precision: 0.9207\n",
      "Epoch 16/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.4492 - accuracy: 0.8705 - binary_accuracy: 0.9982 - recall: 0.8110 - precision: 0.9486 - val_loss: 0.6690 - val_accuracy: 0.8382 - val_binary_accuracy: 0.9979 - val_recall: 0.7928 - val_precision: 0.9203\n",
      "Epoch 17/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.4083 - accuracy: 0.8819 - binary_accuracy: 0.9983 - recall: 0.8256 - precision: 0.9538 - val_loss: 0.6875 - val_accuracy: 0.8346 - val_binary_accuracy: 0.9979 - val_recall: 0.8010 - val_precision: 0.9225\n",
      "Epoch 18/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.3729 - accuracy: 0.8905 - binary_accuracy: 0.9984 - recall: 0.8377 - precision: 0.9537 - val_loss: 0.6837 - val_accuracy: 0.8390 - val_binary_accuracy: 0.9979 - val_recall: 0.8052 - val_precision: 0.9246\n",
      "Epoch 19/100\n",
      "5148/5148 [==============================] - 54s 10ms/sample - loss: 0.3379 - accuracy: 0.9016 - binary_accuracy: 0.9985 - recall: 0.8514 - precision: 0.9579 - val_loss: 0.6905 - val_accuracy: 0.8390 - val_binary_accuracy: 0.9979 - val_recall: 0.8091 - val_precision: 0.9112\n",
      "Epoch 20/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.2945 - accuracy: 0.9133 - binary_accuracy: 0.9987 - recall: 0.8681 - precision: 0.9628 - val_loss: 0.6965 - val_accuracy: 0.8400 - val_binary_accuracy: 0.9979 - val_recall: 0.8115 - val_precision: 0.9103\n",
      "Epoch 21/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.2630 - accuracy: 0.9224 - binary_accuracy: 0.9988 - recall: 0.8812 - precision: 0.9638 - val_loss: 0.6899 - val_accuracy: 0.8431 - val_binary_accuracy: 0.9979 - val_recall: 0.8206 - val_precision: 0.9066\n",
      "Epoch 22/100\n",
      "5148/5148 [==============================] - 52s 10ms/sample - loss: 0.2339 - accuracy: 0.9328 - binary_accuracy: 0.9989 - recall: 0.8948 - precision: 0.9678 - val_loss: 0.7253 - val_accuracy: 0.8377 - val_binary_accuracy: 0.9978 - val_recall: 0.8114 - val_precision: 0.8987\n",
      "Epoch 23/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.1974 - accuracy: 0.9440 - binary_accuracy: 0.9991 - recall: 0.9110 - precision: 0.9730 - val_loss: 0.7132 - val_accuracy: 0.8423 - val_binary_accuracy: 0.9979 - val_recall: 0.8247 - val_precision: 0.9047\n",
      "Epoch 24/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.1576 - accuracy: 0.9592 - binary_accuracy: 0.9993 - recall: 0.9313 - precision: 0.9798 - val_loss: 0.7404 - val_accuracy: 0.8431 - val_binary_accuracy: 0.9978 - val_recall: 0.8276 - val_precision: 0.8942\n",
      "Epoch 25/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.1441 - accuracy: 0.9628 - binary_accuracy: 0.9994 - recall: 0.9379 - precision: 0.9800 - val_loss: 0.7648 - val_accuracy: 0.8418 - val_binary_accuracy: 0.9978 - val_recall: 0.8258 - val_precision: 0.8901\n",
      "Epoch 26/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.1244 - accuracy: 0.9690 - binary_accuracy: 0.9995 - recall: 0.9487 - precision: 0.9832 - val_loss: 0.7918 - val_accuracy: 0.8385 - val_binary_accuracy: 0.9978 - val_recall: 0.8204 - val_precision: 0.8869\n",
      "Epoch 27/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0999 - accuracy: 0.9779 - binary_accuracy: 0.9996 - recall: 0.9625 - precision: 0.9876 - val_loss: 0.7755 - val_accuracy: 0.8444 - val_binary_accuracy: 0.9978 - val_recall: 0.8300 - val_precision: 0.8926\n",
      "Epoch 28/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0825 - accuracy: 0.9845 - binary_accuracy: 0.9997 - recall: 0.9723 - precision: 0.9908 - val_loss: 0.8060 - val_accuracy: 0.8382 - val_binary_accuracy: 0.9978 - val_recall: 0.8283 - val_precision: 0.8879\n",
      "Epoch 29/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0746 - accuracy: 0.9856 - binary_accuracy: 0.9997 - recall: 0.9764 - precision: 0.9910 - val_loss: 0.8087 - val_accuracy: 0.8446 - val_binary_accuracy: 0.9978 - val_recall: 0.8305 - val_precision: 0.8859\n",
      "Epoch 30/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0570 - accuracy: 0.9906 - binary_accuracy: 0.9998 - recall: 0.9848 - precision: 0.9940 - val_loss: 0.8337 - val_accuracy: 0.8467 - val_binary_accuracy: 0.9978 - val_recall: 0.8309 - val_precision: 0.8816\n",
      "Epoch 31/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0442 - accuracy: 0.9943 - binary_accuracy: 0.9999 - recall: 0.9907 - precision: 0.9963 - val_loss: 0.8413 - val_accuracy: 0.8479 - val_binary_accuracy: 0.9978 - val_recall: 0.8345 - val_precision: 0.8798\n",
      "Epoch 32/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0317 - accuracy: 0.9971 - binary_accuracy: 0.9999 - recall: 0.9956 - precision: 0.9979 - val_loss: 0.8550 - val_accuracy: 0.8454 - val_binary_accuracy: 0.9978 - val_recall: 0.8322 - val_precision: 0.8760\n",
      "Epoch 33/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0214 - accuracy: 0.9987 - binary_accuracy: 1.0000 - recall: 0.9984 - precision: 0.9990 - val_loss: 0.8717 - val_accuracy: 0.8454 - val_binary_accuracy: 0.9978 - val_recall: 0.8359 - val_precision: 0.8783\n",
      "Epoch 34/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0147 - accuracy: 0.9993 - binary_accuracy: 1.0000 - recall: 0.9991 - precision: 0.9994 - val_loss: 0.8666 - val_accuracy: 0.8441 - val_binary_accuracy: 0.9978 - val_recall: 0.8360 - val_precision: 0.8783\n",
      "Epoch 35/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0126 - accuracy: 0.9993 - binary_accuracy: 1.0000 - recall: 0.9992 - precision: 0.9994 - val_loss: 0.9048 - val_accuracy: 0.8464 - val_binary_accuracy: 0.9978 - val_recall: 0.8374 - val_precision: 0.8775\n",
      "Epoch 36/100\n",
      "5148/5148 [==============================] - 54s 11ms/sample - loss: 0.0103 - accuracy: 0.9993 - binary_accuracy: 1.0000 - recall: 0.9993 - precision: 0.9994 - val_loss: 0.9193 - val_accuracy: 0.8469 - val_binary_accuracy: 0.9978 - val_recall: 0.8394 - val_precision: 0.8807\n",
      "Epoch 37/100\n",
      "5148/5148 [==============================] - 57s 11ms/sample - loss: 0.0090 - accuracy: 0.9993 - binary_accuracy: 1.0000 - recall: 0.9993 - precision: 0.9993 - val_loss: 0.9288 - val_accuracy: 0.8431 - val_binary_accuracy: 0.9978 - val_recall: 0.8372 - val_precision: 0.8773\n",
      "Epoch 38/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0088 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 0.9365 - val_accuracy: 0.8467 - val_binary_accuracy: 0.9978 - val_recall: 0.8390 - val_precision: 0.8807\n",
      "Epoch 39/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0078 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 0.9361 - val_accuracy: 0.8454 - val_binary_accuracy: 0.9978 - val_recall: 0.8378 - val_precision: 0.8742\n",
      "Epoch 40/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0078 - accuracy: 0.9993 - binary_accuracy: 1.0000 - recall: 0.9992 - precision: 0.9994 - val_loss: 0.9529 - val_accuracy: 0.8454 - val_binary_accuracy: 0.9978 - val_recall: 0.8369 - val_precision: 0.8775\n",
      "Epoch 41/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0243 - accuracy: 0.9958 - binary_accuracy: 0.9999 - recall: 0.9945 - precision: 0.9964 - val_loss: 0.9364 - val_accuracy: 0.8405 - val_binary_accuracy: 0.9977 - val_recall: 0.8301 - val_precision: 0.8670\n",
      "Epoch 42/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.1504 - accuracy: 0.9541 - binary_accuracy: 0.9993 - recall: 0.9409 - precision: 0.9670 - val_loss: 0.9265 - val_accuracy: 0.8274 - val_binary_accuracy: 0.9976 - val_recall: 0.8080 - val_precision: 0.8706\n",
      "Epoch 43/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.1656 - accuracy: 0.9493 - binary_accuracy: 0.9992 - recall: 0.9303 - precision: 0.9662 - val_loss: 0.8237 - val_accuracy: 0.8405 - val_binary_accuracy: 0.9978 - val_recall: 0.8248 - val_precision: 0.8782\n",
      "Epoch 44/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0829 - accuracy: 0.9785 - binary_accuracy: 0.9996 - recall: 0.9688 - precision: 0.9854 - val_loss: 0.8677 - val_accuracy: 0.8379 - val_binary_accuracy: 0.9977 - val_recall: 0.8242 - val_precision: 0.8779\n",
      "Epoch 45/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0398 - accuracy: 0.9932 - binary_accuracy: 0.9999 - recall: 0.9903 - precision: 0.9952 - val_loss: 0.8626 - val_accuracy: 0.8454 - val_binary_accuracy: 0.9978 - val_recall: 0.8295 - val_precision: 0.8777\n",
      "Epoch 46/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0176 - accuracy: 0.9985 - binary_accuracy: 1.0000 - recall: 0.9980 - precision: 0.9988 - val_loss: 0.8894 - val_accuracy: 0.8451 - val_binary_accuracy: 0.9978 - val_recall: 0.8387 - val_precision: 0.8761\n",
      "Epoch 47/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0103 - accuracy: 0.9992 - binary_accuracy: 1.0000 - recall: 0.9991 - precision: 0.9993 - val_loss: 0.9013 - val_accuracy: 0.8464 - val_binary_accuracy: 0.9977 - val_recall: 0.8348 - val_precision: 0.8681\n",
      "Epoch 48/100\n",
      "5148/5148 [==============================] - 52s 10ms/sample - loss: 0.0071 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 0.9120 - val_accuracy: 0.8467 - val_binary_accuracy: 0.9978 - val_recall: 0.8365 - val_precision: 0.8674\n",
      "Epoch 49/100\n",
      "5148/5148 [==============================] - 54s 10ms/sample - loss: 0.0060 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9994 - val_loss: 0.9187 - val_accuracy: 0.8467 - val_binary_accuracy: 0.9978 - val_recall: 0.8367 - val_precision: 0.8699\n",
      "Epoch 50/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0050 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9996 - val_loss: 0.9336 - val_accuracy: 0.8472 - val_binary_accuracy: 0.9977 - val_recall: 0.8344 - val_precision: 0.8673\n",
      "Epoch 51/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0047 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 0.9371 - val_accuracy: 0.8464 - val_binary_accuracy: 0.9978 - val_recall: 0.8364 - val_precision: 0.8683\n",
      "Epoch 52/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0042 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9995 - val_loss: 0.9385 - val_accuracy: 0.8472 - val_binary_accuracy: 0.9978 - val_recall: 0.8387 - val_precision: 0.8682\n",
      "Epoch 53/100\n",
      "5148/5148 [==============================] - 54s 10ms/sample - loss: 0.0039 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 0.9482 - val_accuracy: 0.8436 - val_binary_accuracy: 0.9977 - val_recall: 0.8363 - val_precision: 0.8690\n",
      "Epoch 54/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0035 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 0.9539 - val_accuracy: 0.8462 - val_binary_accuracy: 0.9977 - val_recall: 0.8359 - val_precision: 0.8695\n",
      "Epoch 55/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0036 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9995 - val_loss: 0.9610 - val_accuracy: 0.8474 - val_binary_accuracy: 0.9978 - val_recall: 0.8383 - val_precision: 0.8677\n",
      "Epoch 56/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0032 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 0.9653 - val_accuracy: 0.8456 - val_binary_accuracy: 0.9977 - val_recall: 0.8367 - val_precision: 0.8671\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0031 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9995 - val_loss: 0.9760 - val_accuracy: 0.8479 - val_binary_accuracy: 0.9978 - val_recall: 0.8399 - val_precision: 0.8661\n",
      "Epoch 58/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0032 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9995 - val_loss: 0.9778 - val_accuracy: 0.8464 - val_binary_accuracy: 0.9978 - val_recall: 0.8379 - val_precision: 0.8671\n",
      "Epoch 59/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0038 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 0.9732 - val_accuracy: 0.8472 - val_binary_accuracy: 0.9978 - val_recall: 0.8395 - val_precision: 0.8696\n",
      "Epoch 60/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0044 - accuracy: 0.9993 - binary_accuracy: 1.0000 - recall: 0.9993 - precision: 0.9994 - val_loss: 1.0183 - val_accuracy: 0.8431 - val_binary_accuracy: 0.9977 - val_recall: 0.8372 - val_precision: 0.8650\n",
      "Epoch 61/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0216 - accuracy: 0.9954 - binary_accuracy: 0.9999 - recall: 0.9944 - precision: 0.9962 - val_loss: 0.9828 - val_accuracy: 0.8349 - val_binary_accuracy: 0.9976 - val_recall: 0.8238 - val_precision: 0.8597\n",
      "Epoch 62/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.1170 - accuracy: 0.9639 - binary_accuracy: 0.9994 - recall: 0.9539 - precision: 0.9732 - val_loss: 0.9193 - val_accuracy: 0.8349 - val_binary_accuracy: 0.9977 - val_recall: 0.8184 - val_precision: 0.8695\n",
      "Epoch 63/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.1121 - accuracy: 0.9660 - binary_accuracy: 0.9995 - recall: 0.9558 - precision: 0.9756 - val_loss: 0.9230 - val_accuracy: 0.8374 - val_binary_accuracy: 0.9977 - val_recall: 0.8287 - val_precision: 0.8770\n",
      "Epoch 64/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0692 - accuracy: 0.9817 - binary_accuracy: 0.9997 - recall: 0.9756 - precision: 0.9866 - val_loss: 0.9031 - val_accuracy: 0.8369 - val_binary_accuracy: 0.9977 - val_recall: 0.8248 - val_precision: 0.8717\n",
      "Epoch 65/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0249 - accuracy: 0.9958 - binary_accuracy: 0.9999 - recall: 0.9945 - precision: 0.9968 - val_loss: 0.9108 - val_accuracy: 0.8456 - val_binary_accuracy: 0.9978 - val_recall: 0.8336 - val_precision: 0.8724\n",
      "Epoch 66/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0097 - accuracy: 0.9990 - binary_accuracy: 1.0000 - recall: 0.9988 - precision: 0.9991 - val_loss: 0.9176 - val_accuracy: 0.8505 - val_binary_accuracy: 0.9978 - val_recall: 0.8407 - val_precision: 0.8736\n",
      "Epoch 67/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0057 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 0.9359 - val_accuracy: 0.8500 - val_binary_accuracy: 0.9978 - val_recall: 0.8392 - val_precision: 0.8749\n",
      "Epoch 68/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0038 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 0.9480 - val_accuracy: 0.8472 - val_binary_accuracy: 0.9978 - val_recall: 0.8408 - val_precision: 0.8722\n",
      "Epoch 69/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0035 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 0.9618 - val_accuracy: 0.8477 - val_binary_accuracy: 0.9978 - val_recall: 0.8379 - val_precision: 0.8733\n",
      "Epoch 70/100\n",
      "5148/5148 [==============================] - 54s 10ms/sample - loss: 0.0031 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9996 - val_loss: 0.9631 - val_accuracy: 0.8477 - val_binary_accuracy: 0.9978 - val_recall: 0.8410 - val_precision: 0.8706\n",
      "Epoch 71/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0029 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9994 - val_loss: 0.9761 - val_accuracy: 0.8479 - val_binary_accuracy: 0.9978 - val_recall: 0.8412 - val_precision: 0.8712\n",
      "Epoch 72/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0030 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 0.9810 - val_accuracy: 0.8490 - val_binary_accuracy: 0.9978 - val_recall: 0.8420 - val_precision: 0.8699\n",
      "Epoch 73/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0028 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9996 - val_loss: 0.9864 - val_accuracy: 0.8485 - val_binary_accuracy: 0.9978 - val_recall: 0.8418 - val_precision: 0.8672\n",
      "Epoch 74/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0027 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9996 - val_loss: 0.9960 - val_accuracy: 0.8482 - val_binary_accuracy: 0.9978 - val_recall: 0.8412 - val_precision: 0.8715\n",
      "Epoch 75/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0025 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 0.9912 - val_accuracy: 0.8485 - val_binary_accuracy: 0.9977 - val_recall: 0.8396 - val_precision: 0.8681\n",
      "Epoch 76/100\n",
      "5148/5148 [==============================] - 56s 11ms/sample - loss: 0.0023 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 1.0042 - val_accuracy: 0.8474 - val_binary_accuracy: 0.9977 - val_recall: 0.8389 - val_precision: 0.8693\n",
      "Epoch 77/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0027 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9994 - val_loss: 1.0027 - val_accuracy: 0.8451 - val_binary_accuracy: 0.9978 - val_recall: 0.8399 - val_precision: 0.8687\n",
      "Epoch 78/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0025 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9995 - val_loss: 1.0279 - val_accuracy: 0.8446 - val_binary_accuracy: 0.9977 - val_recall: 0.8396 - val_precision: 0.8656\n",
      "Epoch 79/100\n",
      "5148/5148 [==============================] - 54s 10ms/sample - loss: 0.0031 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9994 - val_loss: 1.0238 - val_accuracy: 0.8495 - val_binary_accuracy: 0.9977 - val_recall: 0.8407 - val_precision: 0.8634\n",
      "Epoch 80/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0047 - accuracy: 0.9990 - binary_accuracy: 1.0000 - recall: 0.9989 - precision: 0.9990 - val_loss: 1.0220 - val_accuracy: 0.8451 - val_binary_accuracy: 0.9977 - val_recall: 0.8369 - val_precision: 0.8660\n",
      "Epoch 81/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0047 - accuracy: 0.9993 - binary_accuracy: 1.0000 - recall: 0.9992 - precision: 0.9993 - val_loss: 1.0232 - val_accuracy: 0.8446 - val_binary_accuracy: 0.9977 - val_recall: 0.8379 - val_precision: 0.8625\n",
      "Epoch 82/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0033 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9994 - val_loss: 1.0123 - val_accuracy: 0.8472 - val_binary_accuracy: 0.9978 - val_recall: 0.8405 - val_precision: 0.8688\n",
      "Epoch 83/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0045 - accuracy: 0.9992 - binary_accuracy: 1.0000 - recall: 0.9991 - precision: 0.9993 - val_loss: 1.0286 - val_accuracy: 0.8462 - val_binary_accuracy: 0.9978 - val_recall: 0.8366 - val_precision: 0.8670\n",
      "Epoch 84/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0098 - accuracy: 0.9979 - binary_accuracy: 1.0000 - recall: 0.9976 - precision: 0.9980 - val_loss: 1.0391 - val_accuracy: 0.8405 - val_binary_accuracy: 0.9976 - val_recall: 0.8292 - val_precision: 0.8574\n",
      "Epoch 85/100\n",
      "5148/5148 [==============================] - 54s 10ms/sample - loss: 0.0191 - accuracy: 0.9958 - binary_accuracy: 0.9999 - recall: 0.9949 - precision: 0.9964 - val_loss: 1.0317 - val_accuracy: 0.8418 - val_binary_accuracy: 0.9977 - val_recall: 0.8316 - val_precision: 0.8612\n",
      "Epoch 86/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0305 - accuracy: 0.9924 - binary_accuracy: 0.9999 - recall: 0.9906 - precision: 0.9936 - val_loss: 1.0285 - val_accuracy: 0.8403 - val_binary_accuracy: 0.9977 - val_recall: 0.8309 - val_precision: 0.8638\n",
      "Epoch 87/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0599 - accuracy: 0.9828 - binary_accuracy: 0.9997 - recall: 0.9791 - precision: 0.9858 - val_loss: 1.0323 - val_accuracy: 0.8290 - val_binary_accuracy: 0.9975 - val_recall: 0.8179 - val_precision: 0.8563\n",
      "Epoch 88/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0882 - accuracy: 0.9730 - binary_accuracy: 0.9996 - recall: 0.9665 - precision: 0.9796 - val_loss: 0.9842 - val_accuracy: 0.8369 - val_binary_accuracy: 0.9977 - val_recall: 0.8219 - val_precision: 0.8675\n",
      "Epoch 89/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0586 - accuracy: 0.9834 - binary_accuracy: 0.9997 - recall: 0.9794 - precision: 0.9875 - val_loss: 0.9552 - val_accuracy: 0.8418 - val_binary_accuracy: 0.9977 - val_recall: 0.8312 - val_precision: 0.8663\n",
      "Epoch 90/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0164 - accuracy: 0.9971 - binary_accuracy: 1.0000 - recall: 0.9963 - precision: 0.9975 - val_loss: 0.9823 - val_accuracy: 0.8431 - val_binary_accuracy: 0.9977 - val_recall: 0.8322 - val_precision: 0.8668\n",
      "Epoch 91/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0082 - accuracy: 0.9989 - binary_accuracy: 1.0000 - recall: 0.9987 - precision: 0.9990 - val_loss: 0.9643 - val_accuracy: 0.8503 - val_binary_accuracy: 0.9978 - val_recall: 0.8412 - val_precision: 0.8732\n",
      "Epoch 92/100\n",
      "5148/5148 [==============================] - 54s 10ms/sample - loss: 0.0034 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 0.9963 - val_accuracy: 0.8487 - val_binary_accuracy: 0.9978 - val_recall: 0.8422 - val_precision: 0.8733\n",
      "Epoch 93/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0028 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9994 - val_loss: 0.9995 - val_accuracy: 0.8500 - val_binary_accuracy: 0.9978 - val_recall: 0.8432 - val_precision: 0.8747\n",
      "Epoch 94/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0025 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9995 - val_loss: 1.0050 - val_accuracy: 0.8515 - val_binary_accuracy: 0.9978 - val_recall: 0.8436 - val_precision: 0.8742\n",
      "Epoch 95/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0021 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9996 - val_loss: 1.0180 - val_accuracy: 0.8477 - val_binary_accuracy: 0.9978 - val_recall: 0.8416 - val_precision: 0.8700\n",
      "Epoch 96/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0019 - accuracy: 0.9997 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 1.0308 - val_accuracy: 0.8490 - val_binary_accuracy: 0.9978 - val_recall: 0.8418 - val_precision: 0.8688\n",
      "Epoch 97/100\n",
      "5148/5148 [==============================] - 54s 10ms/sample - loss: 0.0024 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 1.0308 - val_accuracy: 0.8482 - val_binary_accuracy: 0.9978 - val_recall: 0.8442 - val_precision: 0.8723\n",
      "Epoch 98/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0020 - accuracy: 0.9995 - binary_accuracy: 1.0000 - recall: 0.9995 - precision: 0.9995 - val_loss: 1.0281 - val_accuracy: 0.8492 - val_binary_accuracy: 0.9978 - val_recall: 0.8426 - val_precision: 0.8737\n",
      "Epoch 99/100\n",
      "5148/5148 [==============================] - 52s 10ms/sample - loss: 0.0017 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9997 - val_loss: 1.0401 - val_accuracy: 0.8492 - val_binary_accuracy: 0.9978 - val_recall: 0.8428 - val_precision: 0.8695\n",
      "Epoch 100/100\n",
      "5148/5148 [==============================] - 53s 10ms/sample - loss: 0.0020 - accuracy: 0.9996 - binary_accuracy: 1.0000 - recall: 0.9996 - precision: 0.9996 - val_loss: 1.0418 - val_accuracy: 0.8482 - val_binary_accuracy: 0.9978 - val_recall: 0.8413 - val_precision: 0.8691\n"
     ]
    }
   ],
   "source": [
    "new_experiment.run_experiment(one_hot_reports_train, one_hot_mesh_shifted_train, one_hot_mesh_train, \n",
    "                              one_hot_reports_val, one_hot_mesh_shifted_val, one_hot_mesh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_experiment.save_weights_history(model_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of specific experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'seq2seq_att'\n",
    "model_output_dir = dir + 'trained_models/{}/'.format(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "emb = False\n",
    "epochs = 100\n",
    "hidden_dim = 512\n",
    "\n",
    "param_fn = 'param_seq2seqatt_epochs_{}_hiddendim_{}.pkl'\\\n",
    ".format(epochs, hidden_dim)\n",
    "params = pickle.load(open(model_output_dir + param_fn, 'rb'))\n",
    "\n",
    "old_experiment = Seq2SeqAtt(**params)\n",
    "old_experiment.build_model()\n",
    "old_experiment.load_weights_history(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_start_end(seq, start_token='start', end_token='end'):\n",
    "    stripped_seq = []\n",
    "    for s in seq:\n",
    "        if s not in [start_token, end_token]:\n",
    "            stripped_seq.append(s)\n",
    "    return stripped_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original report:  ['normal', 'heart', 'size', '.', 'anterior', 'osteophytes', 'thoracic', 'spine']\n",
      "True mesh caption:  ['osteophyte', 'thoracic_vertebrae', 'anterior', 'multiple']\n",
      "Predicted mesh caption:  ['osteophyte', 'thoracic_vertebrae', 'anterior', 'multiple']\n",
      "\n",
      "Original report:  ['lungs', 'mildly', 'hyperinflated', 'flattened', 'posterior', 'diaphragm', 'increased', 'retrosternal', 'airspace', '.', 'left', 'hilar', 'calcifications', 'dense', 'left', 'lower', 'lobe', 'nodules', 'suggest', 'previous', 'granulomatous', 'process', '.', 'hyperinflated', 'lungs', ',', 'air', 'trapping', 'versus', 'inspiratory']\n",
      "True mesh caption:  ['calcinosis', 'lung', 'hilum', 'left', 'density', 'lung', 'lower_lobe', 'left', 'round', 'multiple', 'diaphragm', 'posterior', 'flattened', 'right', 'prominent', 'lung', 'hyperdistention', 'mild', 'nodule', 'lung', 'lower_lobe', 'left', 'multiple']\n",
      "Predicted mesh caption:  ['calcinosis', 'lung', 'hilum', 'left', 'density', 'lung', 'lower_lobe', 'left', 'round', 'multiple', 'diaphragm']\n",
      "\n",
      "Original report:  ['well-expanded', 'clear', 'lungs', '.', 'mediastinal', 'contour', 'within', 'normal', 'limits']\n",
      "True mesh caption:  ['normal']\n",
      "Predicted mesh caption:  ['normal']\n",
      "\n",
      "Original report:  ['heart', 'normal', 'size', '.', 'mediastinum', 'unremarkable', '.', 'opacity', 'left', 'midlung', '.', 'lungs', 'clear']\n",
      "True mesh caption:  ['opacity', 'lung', 'lingula']\n",
      "Predicted mesh caption:  ['opacity', 'lung', 'lingula']\n",
      "\n",
      "Original report:  ['noted', 'blunting', 'right', 'pleural', 'space', ',', 'effusion', 'scarring', '.', 'opacity', 'right', 'lung', 'base', 'also', 'appears', 'unchanged', ',', 'scarring', '.', 'heart', 'size', 'appears', 'normal', ',', 'improved', 'prior', 'study', '.', 'stable', 'right', 'basilar', 'scarring', 'right', 'pleural', 'thickening']\n",
      "True mesh caption:  ['cicatrix', 'lung', 'base', 'right', 'cicatrix', 'pleura', 'right', 'opacity', 'lung', 'base', 'right', 'pleura', 'right', 'blunted', 'pleural_effusion', 'right', 'thickening', 'pleura', 'right']\n",
      "Predicted mesh caption:  ['cicatrix', 'lung', 'base', 'right', 'cicatrix', 'pleura', 'right', 'opacity', 'lung', 'base', 'right']\n",
      "\n",
      "Original report:  ['normal', 'cardiomediastinal', 'silhouette', '.', 'intact', 'without', 'acute', 'osseous', 'abnormality', '.', 'lungs', 'clear', 'without', 'focal', 'areas', 'consolidation', ',', 'pleural', 'effusion', ',', 'pneumothorax', '.', 'bilateral', 'costophrenic', 'excluded', 'image', 'pa', 'view', '.sternotomy', 'intact', '.', 'chest', 'radiograph', '.', 'mild']\n",
      "True mesh caption:  ['costophrenic_angle', 'bilateral', 'obscured', 'thoracic_vertebrae', 'degenerative', 'mild']\n",
      "Predicted mesh caption:  ['costophrenic_angle', 'bilateral', 'obscured', 'thoracic_vertebrae', 'degenerative', 'mild']\n",
      "\n",
      "Original report:  ['heart', 'mildly', 'enlarged', '.', 'mediastinal', 'contour', 'pulmonary', 'vascularity', 'within', 'normal', 'limits', '.', 'streaky', 'left', 'basilar', 'airspace', 'opacities', ',', 'compatible', 'atelectasis', 'seen', 'comparison', 'abdomen', 'pelvis', 'ct', '.', 'left', 'upper', 'lung', 'granuloma', '.', 'appear', 'intact', '.', 'left']\n",
      "True mesh caption:  ['cardiomegaly', 'mild', 'granuloma', 'lung', 'upper_lobe', 'left', 'opacity', 'lung', 'base', 'left', 'streaky', 'pulmonary_atelectasis', 'base', 'left']\n",
      "Predicted mesh caption:  ['cardiomegaly', 'mild', 'granuloma', 'lung', 'upper_lobe', 'left', 'opacity', 'lung', 'base', 'left', 'streaky']\n",
      "\n",
      "Original report:  ['lungs', 'clear', 'bilaterally', '.', 'mild', 'cardiomegaly', 'without', 'acute', 'cardiac', 'abnormality', '.', 'visualized', 'osseous', 'structures', 'thorax', 'without', 'acute', 'abnormality', '.', 'mild', 'cardiomegaly', 'without', 'acute', 'cardiopulmonary', 'abnormality']\n",
      "True mesh caption:  ['cardiomegaly', 'mild']\n",
      "Predicted mesh caption:  ['cardiomegaly', 'mild']\n",
      "\n",
      "Original report:  ['heart', 'size', 'normal', '.', 'lungs', 'clear', '.', 'stable', 'mm', 'calcified', 'right', 'midlung', 'nodule']\n",
      "True mesh caption:  ['calcinosis', 'lung', 'middle_lobe', 'right', 'nodule', 'lung', 'middle_lobe', 'right']\n",
      "Predicted mesh caption:  ['calcinosis', 'lung', 'middle_lobe', 'right', 'nodule', 'lung', 'middle_lobe', 'right']\n",
      "\n",
      "Original report:  ['lungs', 'hyperexpanded', '.', 'heart', 'size', 'normal', '.', 'stable', 'degenerative', 'changes', 'thoracic', 'spine', '.', 'emphysematous', 'changes', 'lungs']\n",
      "True mesh caption:  ['lung', 'hyperdistention', 'pulmonary_emphysema', 'thoracic_vertebrae', 'degenerative']\n",
      "Predicted mesh caption:  ['lung', 'hyperdistention', 'pulmonary_emphysema', 'thoracic_vertebrae', 'degenerative']\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    sample = train_df.sample(1)\n",
    "    true_mesh_caption = list(sample.all_mesh)[0]\n",
    "    sample_report = list(sample.pad_text_report)[0]\n",
    "    \n",
    "    sample_report_ids = []\n",
    "    for token in sample_report:\n",
    "        if token in word_to_id.keys():\n",
    "            sample_report_ids.append(word_to_id[token])\n",
    "        else:\n",
    "            sample_report_ids.append(word_to_id[unknown_token])\n",
    "    \n",
    "    sample_report_ids = np.array(sample_report_ids).reshape(1, len(sample_report_ids))\n",
    "    one_hot_sample_report = dpt.one_hot_sequence(sample_report_ids, report_vocab_length)\n",
    "    \n",
    "    #target = predict_sequence(infenc, infdec, one_hot_sample_report, n_steps_out, n_features_out)\n",
    "    target = old_experiment.predict_sequence(one_hot_sample_report)\n",
    "    predicted_mesh_ids = one_hot_decode(target)\n",
    "    predicted_mesh = [id_to_mesh[idx] for idx in predicted_mesh_ids]\n",
    "    \n",
    "    sample_report = strip_start_end(sample_report)\n",
    "    predicted_mesh = strip_start_end(predicted_mesh)\n",
    "    \n",
    "    print('')\n",
    "    print('Original report: ', sample_report)\n",
    "    print('True mesh caption: ', true_mesh_caption)\n",
    "    print('Predicted mesh caption: ', predicted_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate BLEU scores on all trian/val/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def evaluate_model(model, df, report_vocab_length):\n",
    "    actual, predicted = list(), list()\n",
    "    bleu1, bleu2, bleu3, bleu4 = list(), list(), list(), list()\n",
    "\n",
    "    for _, sample in df.iterrows():\n",
    "        true_mesh_caption = sample.all_mesh\n",
    "        sample_report = sample.pad_text_report\n",
    "\n",
    "        sample_report_ids = []\n",
    "        for token in sample_report:\n",
    "            if token in word_to_id.keys():\n",
    "                sample_report_ids.append(word_to_id[token])\n",
    "            else:\n",
    "                sample_report_ids.append(word_to_id[unknown_token])\n",
    "\n",
    "        sample_report_ids = np.array(sample_report_ids).reshape(1, len(sample_report_ids))\n",
    "        one_hot_sample_report = dpt.one_hot_sequence(sample_report_ids, report_vocab_length)\n",
    "\n",
    "        #target = predict_sequence(infenc, infdec, one_hot_sample_report, n_steps_out, n_features_out)\n",
    "        target = model.predict_sequence(one_hot_sample_report)\n",
    "        predicted_mesh_ids = one_hot_decode(target)\n",
    "        predicted_mesh = [id_to_mesh[idx] for idx in predicted_mesh_ids]\n",
    "\n",
    "        # sample_report = strip_start_end(sample_report)\n",
    "        yhat = strip_start_end(predicted_mesh)\n",
    "        reference = true_mesh_caption\n",
    "        \n",
    "        # calculate BLEU score\n",
    "        bleu1.append(sentence_bleu([reference], yhat, weights=(1.0, 0, 0, 0)))\n",
    "        bleu2.append(sentence_bleu([reference], yhat, weights=(0.5, 0.5, 0, 0)))\n",
    "        bleu3.append(sentence_bleu([reference], yhat, weights=(0.3, 0.3, 0.3, 0)))\n",
    "        bleu4.append(sentence_bleu([reference], yhat, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "    \n",
    "        # store actual and predicted\n",
    "        actual.append(reference)\n",
    "        predicted.append(yhat)\n",
    "        \n",
    "    print('BLEU1: ', np.mean(bleu1)*100)\n",
    "    print('BLEU2: ', np.mean(bleu2)*100)\n",
    "    print('BLEU3: ', np.mean(bleu3)*100)\n",
    "    print('BLEU4: ', np.mean(bleu4)*100)\n",
    "    \n",
    "    return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/medic02/users/ag6516/python3env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/vol/medic02/users/ag6516/python3env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/vol/medic02/users/ag6516/python3env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU1:  93.91184482714614\n",
      "BLEU2:  69.49247862087088\n",
      "BLEU3:  60.51783875821691\n",
      "BLEU4:  51.45224917943823\n"
     ]
    }
   ],
   "source": [
    "train_actual, train_predicted = evaluate_model(old_experiment, train_df, report_vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU1:  68.21554414383871\n",
      "BLEU2:  26.26280134482814\n",
      "BLEU3:  15.299111087191413\n",
      "BLEU4:  6.9175551610530075\n"
     ]
    }
   ],
   "source": [
    "val_actual, val_predicted = evaluate_model(old_experiment, val_df, report_vocab_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate ROUGE scores on all train/val/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rouge\n",
    "\n",
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
    "                       max_n=4,\n",
    "                       limit_length=True,\n",
    "                       length_limit=100,\n",
    "                       length_limit_type='words',\n",
    "                       apply_avg='Avg',\n",
    "                       apply_best='Best',\n",
    "                       alpha=0.5, # Default F1_score\n",
    "                       weight_factor=1.2,\n",
    "                       stemming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_results(p, r, f):\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-1:\tP: 99.56\tR: 94.74\tF1: 96.54\n",
      "\trouge-2:\tP: 76.61\tR: 71.54\tF1: 73.40\n",
      "\trouge-3:\tP: 70.41\tR: 65.06\tF1: 66.98\n",
      "\trouge-4:\tP: 62.87\tR: 57.22\tF1: 59.21\n",
      "\trouge-l:\tP: 99.57\tR: 95.39\tF1: 97.03\n",
      "\trouge-w:\tP: 99.38\tR: 72.31\tF1: 81.98\n"
     ]
    }
   ],
   "source": [
    "train_hypotheses = [' '.join(p) for p in train_predicted]\n",
    "train_references = [' '.join(a) for a in train_actual]\n",
    "\n",
    "scores = evaluator.get_scores(train_hypotheses, train_references)\n",
    "\n",
    "for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "    print(prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-1:\tP: 77.44\tR: 73.07\tF1: 73.87\n",
      "\trouge-2:\tP: 33.00\tR: 29.79\tF1: 30.16\n",
      "\trouge-3:\tP: 21.69\tR: 19.61\tF1: 19.67\n",
      "\trouge-4:\tP: 13.23\tR: 11.88\tF1: 11.96\n",
      "\trouge-l:\tP: 77.97\tR: 74.26\tF1: 75.09\n",
      "\trouge-w:\tP: 73.58\tR: 59.60\tF1: 63.71\n"
     ]
    }
   ],
   "source": [
    "val_hypotheses = [' '.join(p) for p in val_predicted]\n",
    "val_references = [' '.join(a) for a in val_actual]\n",
    "\n",
    "scores = evaluator.get_scores(val_hypotheses, val_references)\n",
    "\n",
    "for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "    print(prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
