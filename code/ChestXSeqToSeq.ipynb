{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import data_proc_tools as dpt\n",
    "from utils import plot_tools as pt\n",
    "from utils.custom_metrics import recall, precision, binary_accuracy\n",
    "from utils.custom_metrics import recall_np, precision_np, binary_accuracy_np, multilabel_confusion_matrix\n",
    "from utils.multi_label_text_models import Seq2Seq\n",
    "import random\n",
    "random.seed(42)\n",
    "random_state=1000\n",
    "import pylab\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/vol/medic02/users/ag6516/image_sentence_mapping/'\n",
    "data_dir = dir + 'data/chestx/'\n",
    "sample_size = 'all'\n",
    "data_type = 'processed_balanced'\n",
    "model_output_dir = dir + 'trained_models/chestx/text_seq2seq/train_{}/{}/'.format(sample_size, data_type)\n",
    "data_output_dir = dir + 'data/chestx/{}/'.format(data_type)\n",
    "dicts_dir = dir + 'data/chestx/{}/dicts_pad/'.format(data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and store dictionaries from entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = 'start'\n",
    "end_token = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_pickle(data_output_dir + 'all/all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = Counter()\n",
    "for cap in list(all_df.mesh_caption):\n",
    "    cap = [c for c in cap]\n",
    "    all_words.update(cap)\n",
    "\n",
    "vocab = [k for k, v in all_words.items() if v >= 10]\n",
    "print('Total vocab length: {0}\\nVocab length of words>=10: {1}'.format(len(all_words), len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['proc_mesh_caption'] = all_df.mesh_caption.apply(lambda cap: [w for w in cap if w in vocab])\n",
    "all_df.to_pickle(data_output_dir + 'all/all_proc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = dpt.Vectoriser(data_output_dir+'all/')\n",
    "\n",
    "all_df.tok_reports_padded = all_df.tok_reports_padded.apply(lambda c: [start_token]+c+[end_token])\n",
    "all_df.proc_mesh_caption = all_df.proc_mesh_caption.apply(lambda c: [start_token]+c+[end_token])\n",
    "\n",
    "tok_reports_padded = list(all_df.tok_reports_padded)\n",
    "mesh_captions = list(all_df.proc_mesh_caption)\n",
    "\n",
    "vectoriser.entities_to_vectors(mesh_captions)\n",
    "vectoriser.sentences_to_vectors(tok_reports_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load samples, vectorise text reports and mesh captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_pickle(data_output_dir + 'val/val.pkl')\n",
    "train_df = pd.read_pickle(data_output_dir + 'train_{0}/train_{0}.pkl'.format(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>mesh_caption</th>\n",
       "      <th>text_report</th>\n",
       "      <th>tok_reports_padded</th>\n",
       "      <th>proc_mesh_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR10_IM-0002-1001</td>\n",
       "      <td>[calcified granuloma, lung, upper lobe, right]</td>\n",
       "      <td>the cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>[cardiomediastinal, silhouette, within, normal...</td>\n",
       "      <td>[calcified granuloma, lung, upper lobe, right]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR10_IM-0002-2001</td>\n",
       "      <td>[calcified granuloma, lung, upper lobe, right]</td>\n",
       "      <td>the cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>[cardiomediastinal, silhouette, within, normal...</td>\n",
       "      <td>[calcified granuloma, lung, upper lobe, right]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR1_1_IM-0001-3001</td>\n",
       "      <td>[normal]</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>[cardiac, silhouette, mediastinum, size, withi...</td>\n",
       "      <td>[normal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR1_1_IM-0001-4001</td>\n",
       "      <td>[normal]</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>[cardiac, silhouette, mediastinum, size, withi...</td>\n",
       "      <td>[normal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR1003_IM-0005-2002</td>\n",
       "      <td>[bone diseases, metabolic, spine]</td>\n",
       "      <td>heart size and pulmonary vascularity appear wi...</td>\n",
       "      <td>[heart, size, pulmonary, vascularity, appear, ...</td>\n",
       "      <td>[bone diseases, metabolic, spine]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                imageid                                    mesh_caption  \\\n",
       "0    CXR10_IM-0002-1001  [calcified granuloma, lung, upper lobe, right]   \n",
       "1    CXR10_IM-0002-2001  [calcified granuloma, lung, upper lobe, right]   \n",
       "2   CXR1_1_IM-0001-3001                                        [normal]   \n",
       "3   CXR1_1_IM-0001-4001                                        [normal]   \n",
       "4  CXR1003_IM-0005-2002               [bone diseases, metabolic, spine]   \n",
       "\n",
       "                                         text_report  \\\n",
       "0  the cardiomediastinal silhouette is within nor...   \n",
       "1  the cardiomediastinal silhouette is within nor...   \n",
       "2  the cardiac silhouette and mediastinum size ar...   \n",
       "3  the cardiac silhouette and mediastinum size ar...   \n",
       "4  heart size and pulmonary vascularity appear wi...   \n",
       "\n",
       "                                  tok_reports_padded  \\\n",
       "0  [cardiomediastinal, silhouette, within, normal...   \n",
       "1  [cardiomediastinal, silhouette, within, normal...   \n",
       "2  [cardiac, silhouette, mediastinum, size, withi...   \n",
       "3  [cardiac, silhouette, mediastinum, size, withi...   \n",
       "4  [heart, size, pulmonary, vascularity, appear, ...   \n",
       "\n",
       "                                proc_mesh_caption  \n",
       "0  [calcified granuloma, lung, upper lobe, right]  \n",
       "1  [calcified granuloma, lung, upper lobe, right]  \n",
       "2                                        [normal]  \n",
       "3                                        [normal]  \n",
       "4               [bone diseases, metabolic, spine]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepend start token to mesh captions and reports\n",
    "train_df.tok_reports_padded = train_df.tok_reports_padded.apply(lambda c: [start_token]+c)\n",
    "train_df.mesh_caption = train_df.mesh_caption.apply(lambda c: [start_token]+c)\n",
    "train_df.proc_mesh_caption = train_df.proc_mesh_caption.apply(lambda c: [start_token]+c)\n",
    "\n",
    "val_df.tok_reports_padded = val_df.tok_reports_padded.apply(lambda c: [start_token]+c)\n",
    "val_df.mesh_caption = val_df.mesh_caption.apply(lambda c: [start_token]+c)\n",
    "val_df.proc_mesh_caption = val_df.proc_mesh_caption.apply(lambda c: [start_token]+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>mesh_caption</th>\n",
       "      <th>text_report</th>\n",
       "      <th>tok_reports_padded</th>\n",
       "      <th>proc_mesh_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR10_IM-0002-1001</td>\n",
       "      <td>[start, calcified granuloma, lung, upper lobe,...</td>\n",
       "      <td>the cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>[start, cardiomediastinal, silhouette, within,...</td>\n",
       "      <td>[start, calcified granuloma, lung, upper lobe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR10_IM-0002-2001</td>\n",
       "      <td>[start, calcified granuloma, lung, upper lobe,...</td>\n",
       "      <td>the cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>[start, cardiomediastinal, silhouette, within,...</td>\n",
       "      <td>[start, calcified granuloma, lung, upper lobe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR1_1_IM-0001-3001</td>\n",
       "      <td>[start, normal]</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>[start, cardiac, silhouette, mediastinum, size...</td>\n",
       "      <td>[start, normal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR1_1_IM-0001-4001</td>\n",
       "      <td>[start, normal]</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>[start, cardiac, silhouette, mediastinum, size...</td>\n",
       "      <td>[start, normal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR1003_IM-0005-2002</td>\n",
       "      <td>[start, bone diseases, metabolic, spine]</td>\n",
       "      <td>heart size and pulmonary vascularity appear wi...</td>\n",
       "      <td>[start, heart, size, pulmonary, vascularity, a...</td>\n",
       "      <td>[start, bone diseases, metabolic, spine]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                imageid                                       mesh_caption  \\\n",
       "0    CXR10_IM-0002-1001  [start, calcified granuloma, lung, upper lobe,...   \n",
       "1    CXR10_IM-0002-2001  [start, calcified granuloma, lung, upper lobe,...   \n",
       "2   CXR1_1_IM-0001-3001                                    [start, normal]   \n",
       "3   CXR1_1_IM-0001-4001                                    [start, normal]   \n",
       "4  CXR1003_IM-0005-2002           [start, bone diseases, metabolic, spine]   \n",
       "\n",
       "                                         text_report  \\\n",
       "0  the cardiomediastinal silhouette is within nor...   \n",
       "1  the cardiomediastinal silhouette is within nor...   \n",
       "2  the cardiac silhouette and mediastinum size ar...   \n",
       "3  the cardiac silhouette and mediastinum size ar...   \n",
       "4  heart size and pulmonary vascularity appear wi...   \n",
       "\n",
       "                                  tok_reports_padded  \\\n",
       "0  [start, cardiomediastinal, silhouette, within,...   \n",
       "1  [start, cardiomediastinal, silhouette, within,...   \n",
       "2  [start, cardiac, silhouette, mediastinum, size...   \n",
       "3  [start, cardiac, silhouette, mediastinum, size...   \n",
       "4  [start, heart, size, pulmonary, vascularity, a...   \n",
       "\n",
       "                                   proc_mesh_caption  \n",
       "0  [start, calcified granuloma, lung, upper lobe,...  \n",
       "1  [start, calcified granuloma, lung, upper lobe,...  \n",
       "2                                    [start, normal]  \n",
       "3                                    [start, normal]  \n",
       "4           [start, bone diseases, metabolic, spine]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise vectoriser. if id dictionaries exist, set load_dicts=True\n",
    "train_vectoriser = dpt.Vectoriser(data_output_dir+'train_{}/'.format(sample_size), load_dicts=True, dicts_dir=dicts_dir)\n",
    "val_vectoriser = dpt.Vectoriser(data_output_dir+'val/', load_dicts=True, dicts_dir=dicts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tokenized sentences and entities from df\n",
    "# pad with end token\n",
    "train_tok_reports_padded = list(train_df.tok_reports_padded)\n",
    "train_mesh_captions = list(train_df.proc_mesh_caption)\n",
    "\n",
    "lengths = [len(caption) for caption in train_mesh_captions]\n",
    "max_caption_length = max(lengths)\n",
    "\n",
    "train_mesh_captions_padded = [dpt.pad_sentence(m, max_caption_length, padtok=end_token) for m in train_mesh_captions]\n",
    "\n",
    "val_tok_reports_padded = list(val_df.tok_reports_padded)\n",
    "val_mesh_captions = list(val_df.proc_mesh_caption)\n",
    "\n",
    "val_mesh_captions_padded = [dpt.pad_sentence(m, max_caption_length, padtok=end_token) for m in val_mesh_captions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating list of word ids from loaded dictionaries\n",
      "Creating list of word ids from loaded dictionaries\n"
     ]
    }
   ],
   "source": [
    "# vectorize mesh captions\n",
    "train_vectoriser.entities_to_vectors(train_mesh_captions_padded, save=True)\n",
    "val_vectoriser.entities_to_vectors(val_mesh_captions_padded, save=True)\n",
    "\n",
    "# vectorise reports\n",
    "train_vectoriser.sentences_to_vectors(train_tok_reports_padded)\n",
    "val_vectoriser.sentences_to_vectors(val_tok_reports_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = train_vectoriser.word_to_id\n",
    "id_to_word = train_vectoriser.id_to_word\n",
    "\n",
    "mesh_to_id = train_vectoriser.ent_to_id\n",
    "id_to_mesh = train_vectoriser.id_to_ent\n",
    "\n",
    "report_vocab_length = len(word_to_id)\n",
    "mesh_vocab_length = len(mesh_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "#     dtype='float32')\n",
    "# decoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "#     dtype='float32')\n",
    "# decoder_target_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "#     dtype='float32')\n",
    "\n",
    "# for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "#     for t, char in enumerate(input_text):\n",
    "#         encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "#     for t, char in enumerate(target_text):\n",
    "#         # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "#         decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "#         if t > 0:\n",
    "#             # decoder_target_data will be ahead by one timestep\n",
    "#             # and will not include the start character.\n",
    "# decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays of indixes for input sentences, output entities and shifted output entities (t-1)\n",
    "train_token_ids_array = train_vectoriser.token_ids_array\n",
    "train_mesh_ids_array = train_vectoriser.ents_ids_array\n",
    "train_mesh_ids_array_shifted = [np.concatenate((t[1:],t[-1]), axis=None) for t in train_mesh_ids_array]\n",
    "train_mesh_ids_array_shifted = np.asarray(train_mesh_ids_array_shifted)\n",
    "\n",
    "val_token_ids_array = val_vectoriser.token_ids_array\n",
    "val_mesh_ids_array = val_vectoriser.ents_ids_array\n",
    "val_mesh_ids_array_shifted = [np.concatenate((t[1:],t[-1]), axis=None) for t in val_mesh_ids_array]\n",
    "val_mesh_ids_array_shifted = np.asarray(val_mesh_ids_array_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_seq_length = train_vectoriser.max_sen_len\n",
    "mesh_seq_length = max_caption_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Seq-to-Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 1397)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 105)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 1693696     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  370688      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 105)    26985       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,091,369\n",
      "Trainable params: 2,091,369\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = report_vocab_length\n",
    "output_dim = mesh_vocab_length\n",
    "latent_dim = 256\n",
    "input_seq_length = report_seq_length\n",
    "output_seq_length = mesh_seq_length\n",
    "epochs = 10\n",
    "optimizer = 'adam'\n",
    "batch_size = 128\n",
    "\n",
    "new_experiment = Seq2Seq(epochs=epochs,\n",
    "                               metrics=['accuracy', binary_accuracy,recall,precision],\n",
    "                               optimizer=optimizer,\n",
    "                               batch_size=batch_size, \n",
    "                               input_dim=input_dim,\n",
    "                               output_dim=output_dim,\n",
    "                               latent_dim=latent_dim,\n",
    "                               input_seq_length=input_seq_length,\n",
    "                               output_seq_length=output_seq_length,\n",
    "                               verbose=True)\n",
    "new_experiment.build_model()\n",
    "new_experiment.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batch generators\n",
    "# train_batch_generator = dpt.batch_generator_seq2seq(train_token_ids_array, report_vocab_length, train_mesh_ids_array, \n",
    "#                                                    train_mesh_ids_array_shifted, mesh_vocab_length, batch_size)\n",
    "\n",
    "# val_batch_generator = dpt.batch_generator_seq2seq(val_token_ids_array, report_vocab_length, val_mesh_ids_array, \n",
    "#                                                    val_mesh_ids_array_shifted, mesh_vocab_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or one-hot-encode all at once\n",
    "one_hot_reports_train = dpt.one_hot_sequence(train_token_ids_array, report_vocab_length)\n",
    "one_hot_mesh_train = dpt.one_hot_sequence(train_mesh_ids_array, mesh_vocab_length)\n",
    "one_hot_mesh_shifted_train = dpt.one_hot_sequence(train_mesh_ids_array_shifted, mesh_vocab_length)\n",
    "\n",
    "one_hot_reports_val = dpt.one_hot_sequence(val_token_ids_array, report_vocab_length)\n",
    "one_hot_mesh_val = dpt.one_hot_sequence(val_mesh_ids_array, mesh_vocab_length)\n",
    "one_hot_mesh_shifted_val = dpt.one_hot_sequence(val_mesh_ids_array_shifted, mesh_vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6244 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "6244/6244 [==============================] - 6s 1ms/step - loss: 1.7261 - acc: 0.7356 - binary_accuracy: 0.9952 - recall: 0.5616 - precision: 0.7482 - val_loss: 1.2317 - val_acc: 0.7572 - val_binary_accuracy: 0.9960 - val_recall: 0.6670 - val_precision: 0.8893\n",
      "Epoch 2/10\n",
      "6244/6244 [==============================] - 4s 704us/step - loss: 1.0246 - acc: 0.7794 - binary_accuracy: 0.9964 - recall: 0.6957 - precision: 0.9050 - val_loss: 1.1144 - val_acc: 0.7698 - val_binary_accuracy: 0.9965 - val_recall: 0.6623 - val_precision: 0.9585\n",
      "Epoch 3/10\n",
      "6244/6244 [==============================] - 4s 706us/step - loss: 0.9150 - acc: 0.7907 - binary_accuracy: 0.9970 - recall: 0.7194 - precision: 0.9496 - val_loss: 1.0026 - val_acc: 0.7765 - val_binary_accuracy: 0.9969 - val_recall: 0.7095 - val_precision: 0.9466\n",
      "Epoch 4/10\n",
      "6244/6244 [==============================] - 4s 708us/step - loss: 0.8181 - acc: 0.8095 - binary_accuracy: 0.9972 - recall: 0.7266 - precision: 0.9670 - val_loss: 0.9047 - val_acc: 0.8000 - val_binary_accuracy: 0.9970 - val_recall: 0.7205 - val_precision: 0.9551\n",
      "Epoch 5/10\n",
      "6244/6244 [==============================] - 4s 709us/step - loss: 0.7432 - acc: 0.8276 - binary_accuracy: 0.9973 - recall: 0.7454 - precision: 0.9627 - val_loss: 0.8416 - val_acc: 0.8135 - val_binary_accuracy: 0.9971 - val_recall: 0.7368 - val_precision: 0.9520\n",
      "Epoch 6/10\n",
      "6244/6244 [==============================] - 4s 709us/step - loss: 0.6982 - acc: 0.8343 - binary_accuracy: 0.9974 - recall: 0.7533 - precision: 0.9621 - val_loss: 0.8103 - val_acc: 0.8170 - val_binary_accuracy: 0.9972 - val_recall: 0.7387 - val_precision: 0.9603\n",
      "Epoch 7/10\n",
      "6244/6244 [==============================] - 4s 712us/step - loss: 0.6676 - acc: 0.8371 - binary_accuracy: 0.9974 - recall: 0.7596 - precision: 0.9636 - val_loss: 0.7851 - val_acc: 0.8185 - val_binary_accuracy: 0.9972 - val_recall: 0.7415 - val_precision: 0.9554\n",
      "Epoch 8/10\n",
      "6244/6244 [==============================] - 4s 710us/step - loss: 0.6441 - acc: 0.8393 - binary_accuracy: 0.9975 - recall: 0.7624 - precision: 0.9651 - val_loss: 0.7542 - val_acc: 0.8205 - val_binary_accuracy: 0.9973 - val_recall: 0.7443 - val_precision: 0.9584\n",
      "Epoch 9/10\n",
      "6244/6244 [==============================] - 4s 711us/step - loss: 0.6215 - acc: 0.8417 - binary_accuracy: 0.9975 - recall: 0.7733 - precision: 0.9609 - val_loss: 0.7276 - val_acc: 0.8263 - val_binary_accuracy: 0.9973 - val_recall: 0.7525 - val_precision: 0.9582\n",
      "Epoch 10/10\n",
      "6244/6244 [==============================] - 4s 710us/step - loss: 0.5998 - acc: 0.8432 - binary_accuracy: 0.9977 - recall: 0.7933 - precision: 0.9566 - val_loss: 0.7038 - val_acc: 0.8240 - val_binary_accuracy: 0.9974 - val_recall: 0.7808 - val_precision: 0.9347\n"
     ]
    }
   ],
   "source": [
    "new_experiment.run_experiment(one_hot_reports_train, one_hot_mesh_train, one_hot_mesh_shifted_train, \n",
    "                              one_hot_reports_val, one_hot_mesh_val, one_hot_mesh_shifted_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_experiment.save_weights_history(model_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of specific experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 'all'\n",
    "data_type = 'processed_balanced'\n",
    "model_output_dir = dir + 'trained_models/chestx/text_seq2seq/train_{}/{}/'.format(sample_size,data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "latent_dim = 256\n",
    "\n",
    "param_fn = 'param_cnn_epochs_{}_latentdim_{}.json'\\\n",
    ".format(epochs, latent_dim)\n",
    "params = json.load(open(model_output_dir + param_fn, 'r'))\n",
    "\n",
    "old_experiment = Seq2Seq(**params)\n",
    "old_experiment.build_model()\n",
    "old_experiment.load_weights_history(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = val_df.sample(1)\n",
    "true_mesh_caption = list(sample.proc_mesh_caption)[0]\n",
    "sample_report = list(sample.tok_reports_padded)[0]\n",
    "sample_report_ids = [word_to_id[word] for word in sample_report]\n",
    "sample_report_ids = np.array(sample_report_ids)\n",
    "sample_report_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'lung', 'volumes', 'low', 'interval', 'patchy', 'infiltrate', 'developed', 'right', 'lower', 'lobe', 'heart', 'pulmonary', 'xxxx', 'normal', 'xxxx', 'xxxx', 'patchy', 'right', 'lower', 'lobe', 'infiltrate', 'consistent', 'pneumonia', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "True mesh caption:  ['start', 'infiltrate', 'lung', 'lower lobe', 'right', 'patchy']\n",
      "Predicted mesh caption:  normal.\n",
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'heart', 'normal', 'size', 'contour', 'vague', 'area', 'airspace', 'disease', 'identified', 'within', 'right', 'midlung', 'pa', 'view', 'well-demonstrated', 'lateral', 'view', 'pneumothorax', 'effusion', 'vague', 'area', 'focal', 'airspace', 'disease', 'within', 'right', 'midlung', 'concern', 'pneumonia', 'recommend', 'followup', 'appropriate', 'treatment', 'document', 'complete', 'resolution', '.', '.', '.', '.']\n",
      "True mesh caption:  ['start', 'airspace disease', 'lung', 'middle lobe', 'right', 'focal']\n",
      "Predicted mesh caption:  normal.\n",
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'heart', 'normal', 'size', 'stable', 'appearance', 'coronary', 'stent', 'xxxx', 'sternotomy', 'changes', 'present', 'focal', 'consolidation', 'pneumothorax', 'pleural', 'effusion', 'mild', 'degenerative', 'changes', 'thoracic', 'spine', 'acute', 'cardiopulmonary', 'abnormalities', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "True mesh caption:  ['start', 'stents', 'coronary vessels']\n",
      "Predicted mesh caption:  normal.\n",
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'hyperexpansion', 'mild', 'flattening', 'diaphragm', 'cardiomediastinal', 'silhouette', 'normal', 'pulmonary', 'vasculature', 'xxxx', 'normal', 'consolidation', 'pneumothorax', 'large', 'pleural', 'effusion', 'osseous', 'structures', 'soft', 'tissues', 'normal', 'contrast', 'retained', 'within', 'renal', 'collecting', 'xxxx', '1', 'acute', 'cardiopulmonary', 'disease', '2', 'emphysematous', 'changes', '3', 'retained', 'contrast', 'within', 'renal', 'collecting']\n",
      "True mesh caption:  ['start', 'abdomen']\n",
      "Predicted mesh caption:  normal.\n",
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'cardiomegaly', 'prominent', 'xxxx', 'stable', 'low', 'lung', 'volumes', 'pneumothorax', 'minimal', 'right', 'costophrenic', 'xxxx', 'blunting', 'focal', 'infiltrates', 'cardiomegaly', 'xxxx', 'right', 'pleural', 'effusion', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "True mesh caption:  ['start', 'cardiomegaly']\n",
      "Predicted mesh caption:  normal.\n",
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'lungs', 'clear', 'heart', 'pulmonary', 'xxxx', 'normal', 'pleural', 'spaces', 'clear', 'mediastinal', 'contours', 'normal', 'acute', 'cardiopulmonary', 'disease', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "True mesh caption:  ['start', 'normal']\n",
      "Predicted mesh caption:  normal.\n",
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'pneumothorax', 'pleural', 'effusion', 'airspace', 'consolidation', 'cardiomediastinal', 'size', 'within', 'normal', 'limits', 'pulmonary', 'vasculature', 'normal', 'old', 'rib', 'fractures', 'healed', 'stable', 'increased', 'density', 'overlying', 'lower', 'mediastinum', 'unchanged', 'xxxx', 'due', 'hiatal', 'hernia', 'seen', 'xxxx', 'examination', 'acute', 'cardiopulmonary', 'abnormality', '.', '.', '.', '.', '.', '.']\n",
      "True mesh caption:  ['start', 'density', 'mediastinum']\n",
      "Predicted mesh caption:  normal.\n",
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'heart', 'size', 'mediastinal', 'contours', 'appear', 'within', 'normal', 'limits', 'eventration', 'right', 'hemidiaphragm', 'focal', 'lung', 'consolidation', 'pleural', 'effusion', 'pneumothorax', 'acute', 'bony', 'abnormality', 'acute', 'cardiopulmonary', 'abnormality', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "True mesh caption:  ['start', 'diaphragmatic eventration', 'right']\n",
      "Predicted mesh caption:  normal.\n",
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'cardiomediastinal', 'silhouette', 'within', 'normal', 'limits', 'size', 'contour', 'lungs', 'normally', 'inflated', 'without', 'evidence', 'focal', 'airspace', 'disease', 'pleural', 'effusion', 'pneumothorax', 'cholecystectomy', 'clips', 'overlie', 'right', 'upper', 'quadrant', 'acute', 'bone', 'abnormality', 'acute', 'cardiopulmonary', 'process', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "True mesh caption:  ['start', 'normal']\n",
      "Predicted mesh caption:  normal.\n",
      "(1, 256)\n",
      "(1, 1, 105)\n",
      "(1, 1, 105)\n",
      "-\n",
      "Original report:  ['start', 'heart', 'size', 'normal', 'mediastinal', 'silhouette', 'pulmonary', 'vascularity', 'within', 'normal', 'limits', 'lungs', 'clear', 'without', 'interval', 'consolidation', 'pleural', 'effusion', 'pneumothorax', 'mild', 'degenerative', 'endplate', 'spurring', 'mid', 'thoracic', 'spine', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "True mesh caption:  ['start', 'osteophyte', 'thoracic vertebrae', 'degenerative', 'mild']\n",
      "Predicted mesh caption:  normal.\n"
     ]
    }
   ],
   "source": [
    "# generate samples\n",
    "for seq_index in range(10):\n",
    "    sample = val_df.sample(1)\n",
    "    true_mesh_caption = list(sample.proc_mesh_caption)[0]\n",
    "    sample_report = list(sample.tok_reports_padded)[0]\n",
    "    sample_report_ids = [word_to_id[word] for word in sample_report]\n",
    "    sample_report_ids = np.array(sample_report_ids).reshape(1, len(sample_report_ids))\n",
    "    one_hot_sample_report = dpt.one_hot_sequence(sample_report_ids, report_vocab_length)\n",
    "    input_seq = one_hot_sample_report\n",
    "    decoded_sentence = old_experiment.decode_sequence(input_seq, id_to_mesh, mesh_to_id)\n",
    "    print('-')\n",
    "    print('Original report: ', sample_report)\n",
    "    print('True mesh caption: ', true_mesh_caption)\n",
    "    print('Predicted mesh caption: ', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pred_mesh_val = old_experiment.model.predict(reports_val)\n",
    "_pred_mesh_train = old_experiment.model.predict(reports_train)\n",
    "\n",
    "pred_mesh_val = np.array([_pred_mesh_val > 0.5])*1.0\n",
    "pred_mesh_val = pred_mesh_val[0]\n",
    "\n",
    "pred_mesh_train = np.array([_pred_mesh_train > 0.5])*1.0\n",
    "pred_mesh_train = pred_mesh_train[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
