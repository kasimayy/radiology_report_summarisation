{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import pickle\n",
    "import sys\n",
    "# sys.path.append(\"..\")\n",
    "from utils import data_proc_tools as dpt\n",
    "from utils import plot_tools as pt\n",
    "from utils.custom_metrics import recall, precision, binary_accuracy\n",
    "from utils.custom_metrics import recall_np, precision_np, binary_accuracy_np, multilabel_confusion_matrix\n",
    "from utils.text_sum_models import Seq2Seq\n",
    "import random\n",
    "random.seed(42)\n",
    "random_state=1000\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import pylab\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D, SeparableConv1D\n",
    "from keras.layers import Flatten, Dropout, Input, LSTM, BatchNormalization, Activation, TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dir = '/vol/medic02/users/ag6516/radiology_report_summarisation/'\n",
    "data_dir = dir + 'data/'\n",
    "\n",
    "aug = 'aug'\n",
    "\n",
    "model_output_dir = dir + 'trained_models/seq2seq/'\n",
    "\n",
    "train_df = pd.read_pickle(data_dir + 'train/{}_train.pkl'.format(aug))\n",
    "val_df = pd.read_pickle(data_dir + 'val/val.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare sequence data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>examid</th>\n",
       "      <th>report</th>\n",
       "      <th>all_mesh</th>\n",
       "      <th>single_mesh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR1000_IM-0003</td>\n",
       "      <td>[increased, opacity, within, right, upper, lobe, possible, mass, associated, area, atelectasis, focal, consolidation, ., cardiac, silhouette, within, normal, limits, ., opacity, left, midlung, overlying, posterior, left, 5th, rib, may, represent, focal, airspace, disease, ., increased, opacity, right, upper, lobe, associated, atelectasis, may, represent, focal, consolidation, mass, lesion, atelectasis, ., recommend, chest, ct, evaluation, ., opacity, overlying, left, 5th, rib, may, represent, focal, airspace, disease]</td>\n",
       "      <td>[opacity, lung, lingula, opacity, lung, upper_lobe, right, pulmonary_atelectasis, upper_lobe, right]</td>\n",
       "      <td>[opacity, lung, upper_lobe, right]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR1001_IM-0004</td>\n",
       "      <td>[interstitial, markings, diffusely, prominent, throughout, lungs, ., heart, size, normal, ., pulmonary, normal, ., diffuse, fibrosis]</td>\n",
       "      <td>[diffuse, markings, lung, bilateral, interstitial, diffuse, prominent]</td>\n",
       "      <td>[markings, lung, bilateral, interstitial, diffuse, prominent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR1002_IM-0004</td>\n",
       "      <td>[status, post, left, mastectomy, ., heart, size, normal, ., lungs, clear]</td>\n",
       "      <td>[left]</td>\n",
       "      <td>[left]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR1003_IM-0005</td>\n",
       "      <td>[heart, size, pulmonary, vascularity, appear, within, normal, limits, ., retrocardiac, soft, tissue, density, present, ., appears, air, within, suggest, represents, hiatal, hernia, ., vascular, calcification, noted, ., calcified, granuloma, seen, ., interval, development, bandlike, opacity, left, lung, base, ., may, represent, atelectasis, ., osteopenia, present, spine, ., retrocardiac, soft, tissue, density, ., appearance, suggests, hiatal, hernia, ., left, base, bandlike, opacity, ., appearance, suggests, atelectasis]</td>\n",
       "      <td>[bone_diseases_metabolic, spine, calcified_granuloma, calcinosis, blood_vessels, density, retrocardiac, opacity, lung, base, left]</td>\n",
       "      <td>[opacity, lung, base, left]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR1004_IM-0005</td>\n",
       "      <td>[heart, ,, pulmonary, mediastinum, within, normal, limits, ., aorta, tortuous, ectatic, ., degenerative, changes, acromioclavicular, joints, ., degenerative, changes, spine, ., ivc, identified]</td>\n",
       "      <td>[aorta, tortuous, catheters_indwelling, shoulder, bilateral, degenerative, spine, degenerative]</td>\n",
       "      <td>[shoulder, bilateral, degenerative]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            examid  \\\n",
       "0  CXR1000_IM-0003   \n",
       "1  CXR1001_IM-0004   \n",
       "2  CXR1002_IM-0004   \n",
       "3  CXR1003_IM-0005   \n",
       "4  CXR1004_IM-0005   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          report  \\\n",
       "0  [increased, opacity, within, right, upper, lobe, possible, mass, associated, area, atelectasis, focal, consolidation, ., cardiac, silhouette, within, normal, limits, ., opacity, left, midlung, overlying, posterior, left, 5th, rib, may, represent, focal, airspace, disease, ., increased, opacity, right, upper, lobe, associated, atelectasis, may, represent, focal, consolidation, mass, lesion, atelectasis, ., recommend, chest, ct, evaluation, ., opacity, overlying, left, 5th, rib, may, represent, focal, airspace, disease]     \n",
       "1  [interstitial, markings, diffusely, prominent, throughout, lungs, ., heart, size, normal, ., pulmonary, normal, ., diffuse, fibrosis]                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "2  [status, post, left, mastectomy, ., heart, size, normal, ., lungs, clear]                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "3  [heart, size, pulmonary, vascularity, appear, within, normal, limits, ., retrocardiac, soft, tissue, density, present, ., appears, air, within, suggest, represents, hiatal, hernia, ., vascular, calcification, noted, ., calcified, granuloma, seen, ., interval, development, bandlike, opacity, left, lung, base, ., may, represent, atelectasis, ., osteopenia, present, spine, ., retrocardiac, soft, tissue, density, ., appearance, suggests, hiatal, hernia, ., left, base, bandlike, opacity, ., appearance, suggests, atelectasis]   \n",
       "4  [heart, ,, pulmonary, mediastinum, within, normal, limits, ., aorta, tortuous, ectatic, ., degenerative, changes, acromioclavicular, joints, ., degenerative, changes, spine, ., ivc, identified]                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "                                                                                                                             all_mesh  \\\n",
       "0  [opacity, lung, lingula, opacity, lung, upper_lobe, right, pulmonary_atelectasis, upper_lobe, right]                                 \n",
       "1  [diffuse, markings, lung, bilateral, interstitial, diffuse, prominent]                                                               \n",
       "2  [left]                                                                                                                               \n",
       "3  [bone_diseases_metabolic, spine, calcified_granuloma, calcinosis, blood_vessels, density, retrocardiac, opacity, lung, base, left]   \n",
       "4  [aorta, tortuous, catheters_indwelling, shoulder, bilateral, degenerative, spine, degenerative]                                      \n",
       "\n",
       "                                                     single_mesh  \n",
       "0  [opacity, lung, upper_lobe, right]                             \n",
       "1  [markings, lung, bilateral, interstitial, diffuse, prominent]  \n",
       "2  [left]                                                         \n",
       "3  [opacity, lung, base, left]                                    \n",
       "4  [shoulder, bilateral, degenerative]                            "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence empty\n",
      "Sequence empty\n",
      "Sequence empty\n",
      "Sequence empty\n",
      "Sequence empty\n",
      "Sequence empty\n",
      "Sequence empty\n"
     ]
    }
   ],
   "source": [
    "# prepend and append start and end tokens to mesh captions and text reports\n",
    "start_token = 'start'\n",
    "end_token = 'end'\n",
    "unknown_token = '**unknown**'\n",
    "max_mesh_length = 13 # avg. + 1std. + start + end\n",
    "max_report_length = 37 # avg. + 1std. + start + end\n",
    "\n",
    "train_df['pad_mesh_caption'] = train_df.all_mesh.apply(lambda x: dpt.pad_sequence(x, max_mesh_length, start_token, end_token))\n",
    "train_df['pad_text_report'] = train_df.report.apply(lambda x: dpt.pad_sequence(x, max_report_length, start_token, end_token))\n",
    "\n",
    "val_df['pad_mesh_caption'] = val_df.all_mesh.apply(lambda x: dpt.pad_sequence(x, max_mesh_length, start_token, end_token))\n",
    "val_df['pad_text_report'] = val_df.report.apply(lambda x: dpt.pad_sequence(x, max_report_length, start_token, end_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorise text reports and mesh captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating list of mesh ids from loaded dictionaries\n"
     ]
    }
   ],
   "source": [
    "train_mesh = list(train_df.pad_mesh_caption)\n",
    "train_reports = list(train_df.pad_text_report)\n",
    "\n",
    "# vectorize mesh captions\n",
    "dpt.mesh_to_vectors(train_mesh, dicts_dir=data_dir+'dicts/', load_dicts=True, save=True, output_dir=data_dir+'train/')\n",
    "\n",
    "# vectorise reports\n",
    "dpt.reports_to_vectors(train_reports, dicts_dir=data_dir+'dicts/', load_dicts=True, save=True, output_dir=data_dir+'train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating list of mesh ids from loaded dictionaries\n"
     ]
    }
   ],
   "source": [
    "val_reports = list(val_df.pad_text_report)\n",
    "val_mesh = list(val_df.pad_mesh_caption)\n",
    "\n",
    "# vectorise val reports + mesh using the same dict as created for train\n",
    "dpt.mesh_to_vectors(val_mesh, dicts_dir=data_dir+'dicts/', load_dicts=True, save=True, output_dir=data_dir+'val/')\n",
    "dpt.reports_to_vectors(val_reports, dicts_dir=data_dir+'dicts/', load_dicts=True, save=True, output_dir=data_dir+'val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, id_to_word = dpt.load_report_dicts(data_dir+'dicts/')\n",
    "mesh_to_id, id_to_mesh = dpt.load_mesh_dicts(data_dir+'dicts/')\n",
    "\n",
    "report_vocab_length = len(word_to_id)\n",
    "mesh_vocab_length = len(mesh_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1475, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_vocab_length, mesh_vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays of indixes for input sentences, output entities and shifted output entities (t-1)\n",
    "train_token_ids_array = np.load(data_dir + 'train/token_ids_array.npy')\n",
    "train_mesh_ids_array = np.load(data_dir + 'train/mesh_ids_array.npy')\n",
    "train_mesh_ids_array_shifted =[np.concatenate((mesh_to_id[start_token], t[:-1]), axis=None) for t in train_mesh_ids_array]\n",
    "train_mesh_ids_array_shifted = np.asarray(train_mesh_ids_array_shifted)\n",
    "\n",
    "val_token_ids_array = np.load(data_dir + 'val/token_ids_array.npy')\n",
    "val_mesh_ids_array = np.load(data_dir + 'val/mesh_ids_array.npy')\n",
    "val_mesh_ids_array_shifted = [np.concatenate((mesh_to_id[start_token], t[:-1]), axis=None) for t in val_mesh_ids_array]\n",
    "val_mesh_ids_array_shifted = np.asarray(val_mesh_ids_array_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1448,  568, 1409,  420, 1109,  563,  501, 1166, 1092,  380, 1363,\n",
       "       1472,   50,  197,  227, 1400,  191,  420,  955,  238,  227, 1409,\n",
       "        117,  323, 1264,  121,  117, 1249,  232, 1157, 1300,   50,  362,\n",
       "         71,  227,  568,  917])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token_ids_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'increased', 'opacity', 'within', 'right', 'upper', 'lobe', 'possible', 'mass', 'associated', 'area', 'atelectasis', 'focal', 'consolidation', '.', 'cardiac', 'silhouette', 'within', 'normal', 'limits', '.', 'opacity', 'left', 'midlung', 'overlying', 'posterior', 'left', '5th', 'rib', 'may', 'represent', 'focal', 'airspace', 'disease', '.', 'increased', 'end']\n"
     ]
    }
   ],
   "source": [
    "print([id_to_word[idx] for idx in train_token_ids_array[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'opacity', 'lung', 'lingula', 'opacity', 'lung', 'upper_lobe', 'right', 'pulmonary_atelectasis', 'upper_lobe', 'right', 'end', 'end']\n"
     ]
    }
   ],
   "source": [
    "print([id_to_mesh[idx] for idx in train_mesh_ids_array[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'start', 'opacity', 'lung', 'lingula', 'opacity', 'lung', 'upper_lobe', 'right', 'pulmonary_atelectasis', 'upper_lobe', 'right', 'end']\n"
     ]
    }
   ],
   "source": [
    "print([id_to_mesh[idx] for idx in train_mesh_ids_array_shifted[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encode\n",
    "one_hot_reports_train = dpt.one_hot_sequence(train_token_ids_array, report_vocab_length)\n",
    "one_hot_mesh_train = dpt.one_hot_sequence(train_mesh_ids_array, mesh_vocab_length)\n",
    "one_hot_mesh_shifted_train = dpt.one_hot_sequence(train_mesh_ids_array_shifted, mesh_vocab_length)\n",
    "\n",
    "one_hot_reports_val = dpt.one_hot_sequence(val_token_ids_array, report_vocab_length)\n",
    "one_hot_mesh_val = dpt.one_hot_sequence(val_mesh_ids_array, mesh_vocab_length)\n",
    "one_hot_mesh_shifted_val = dpt.one_hot_sequence(val_mesh_ids_array_shifted, mesh_vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5148, 37, 1475), (5148, 13, 128), (5148, 13, 128))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_reports_train.shape, one_hot_mesh_train.shape, one_hot_mesh_shifted_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Seq-to-Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(128, 37, 1475)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(128, 512), (128, 5 4071424     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   multiple             1312768     input_8[0][0]                    \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 multiple             65664       lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,449,856\n",
      "Trainable params: 5,449,856\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(word_to_id)\n",
    "output_dim = len(mesh_to_id)\n",
    "hidden_dim = 512\n",
    "input_seq_length = max_report_length\n",
    "output_seq_length = max_mesh_length\n",
    "epochs = 50\n",
    "optimizer = 'adam'\n",
    "loss='categorical_crossentropy'\n",
    "batch_size = 128\n",
    "\n",
    "new_experiment = Seq2Seq(epochs=epochs,\n",
    "                               metrics=['accuracy', binary_accuracy,recall,precision],\n",
    "                               optimizer=optimizer,\n",
    "                               loss=loss,\n",
    "                               batch_size=batch_size, \n",
    "                               input_dim=input_dim,\n",
    "                               output_dim=output_dim,\n",
    "                               hidden_dim=hidden_dim,\n",
    "                               input_seq_length=input_seq_length,\n",
    "                               output_seq_length=output_seq_length,\n",
    "                               verbose=True)\n",
    "new_experiment.build_model()\n",
    "new_experiment.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batch generators\n",
    "# train_batch_generator = dpt.batch_generator_seq2seq(train_token_ids_array, report_vocab_length, train_mesh_ids_array, \n",
    "#                                                    train_mesh_ids_array_shifted, mesh_vocab_length, batch_size)\n",
    "\n",
    "# val_batch_generator = dpt.batch_generator_seq2seq(val_token_ids_array, report_vocab_length, val_mesh_ids_array, \n",
    "#                                                    val_mesh_ids_array_shifted, mesh_vocab_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "5148/5148 [==============================] - 23s 5ms/sample - loss: 2.4062 - accuracy: 0.5744 - binary_accuracy: 0.9947 - recall: 0.4575 - precision: 0.7400 - val_loss: 1.6555 - val_accuracy: 0.6926 - val_binary_accuracy: 0.9961 - val_recall: 0.5648 - val_precision: 0.9065\n",
      "Epoch 2/50\n",
      "5148/5148 [==============================] - 19s 4ms/sample - loss: 1.7693 - accuracy: 0.6328 - binary_accuracy: 0.9959 - recall: 0.5381 - precision: 0.9083 - val_loss: 1.4552 - val_accuracy: 0.7033 - val_binary_accuracy: 0.9965 - val_recall: 0.5583 - val_precision: 0.9948\n",
      "Epoch 3/50\n",
      "5148/5148 [==============================] - 19s 4ms/sample - loss: 1.5798 - accuracy: 0.6526 - binary_accuracy: 0.9964 - recall: 0.5706 - precision: 0.9431 - val_loss: 1.2632 - val_accuracy: 0.7154 - val_binary_accuracy: 0.9970 - val_recall: 0.6613 - val_precision: 0.9357\n",
      "Epoch 4/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 1.4294 - accuracy: 0.6756 - binary_accuracy: 0.9966 - recall: 0.5875 - precision: 0.9534 - val_loss: 1.1422 - val_accuracy: 0.7362 - val_binary_accuracy: 0.9972 - val_recall: 0.6751 - val_precision: 0.9499\n",
      "Epoch 5/50\n",
      "5148/5148 [==============================] - 19s 4ms/sample - loss: 1.2586 - accuracy: 0.7041 - binary_accuracy: 0.9967 - recall: 0.6104 - precision: 0.9576 - val_loss: 1.0305 - val_accuracy: 0.7636 - val_binary_accuracy: 0.9973 - val_recall: 0.6672 - val_precision: 0.9826\n",
      "Epoch 6/50\n",
      "5148/5148 [==============================] - 19s 4ms/sample - loss: 1.1197 - accuracy: 0.7291 - binary_accuracy: 0.9969 - recall: 0.6318 - precision: 0.9598 - val_loss: 0.9350 - val_accuracy: 0.7728 - val_binary_accuracy: 0.9974 - val_recall: 0.6938 - val_precision: 0.9655\n",
      "Epoch 7/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 1.0208 - accuracy: 0.7466 - binary_accuracy: 0.9970 - recall: 0.6498 - precision: 0.9555 - val_loss: 0.9567 - val_accuracy: 0.7697 - val_binary_accuracy: 0.9973 - val_recall: 0.6793 - val_precision: 0.9737\n",
      "Epoch 8/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.9763 - accuracy: 0.7527 - binary_accuracy: 0.9971 - recall: 0.6601 - precision: 0.9471 - val_loss: 0.8588 - val_accuracy: 0.7877 - val_binary_accuracy: 0.9975 - val_recall: 0.7297 - val_precision: 0.9341\n",
      "Epoch 9/50\n",
      "5148/5148 [==============================] - 19s 4ms/sample - loss: 0.8923 - accuracy: 0.7670 - binary_accuracy: 0.9972 - recall: 0.6833 - precision: 0.9445 - val_loss: 0.8168 - val_accuracy: 0.7951 - val_binary_accuracy: 0.9975 - val_recall: 0.7335 - val_precision: 0.9375\n",
      "Epoch 10/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.8354 - accuracy: 0.7775 - binary_accuracy: 0.9973 - recall: 0.6962 - precision: 0.9444 - val_loss: 0.8001 - val_accuracy: 0.7992 - val_binary_accuracy: 0.9976 - val_recall: 0.7376 - val_precision: 0.9420\n",
      "Epoch 11/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.8033 - accuracy: 0.7832 - binary_accuracy: 0.9973 - recall: 0.7029 - precision: 0.9421 - val_loss: 0.7888 - val_accuracy: 0.7972 - val_binary_accuracy: 0.9976 - val_recall: 0.7298 - val_precision: 0.9545\n",
      "Epoch 12/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.7631 - accuracy: 0.7912 - binary_accuracy: 0.9974 - recall: 0.7107 - precision: 0.9430 - val_loss: 0.7694 - val_accuracy: 0.8031 - val_binary_accuracy: 0.9976 - val_recall: 0.7460 - val_precision: 0.9344\n",
      "Epoch 13/50\n",
      "5148/5148 [==============================] - 19s 4ms/sample - loss: 0.7212 - accuracy: 0.8008 - binary_accuracy: 0.9975 - recall: 0.7204 - precision: 0.9415 - val_loss: 0.7693 - val_accuracy: 0.8069 - val_binary_accuracy: 0.9976 - val_recall: 0.7408 - val_precision: 0.9438\n",
      "Epoch 14/50\n",
      "5148/5148 [==============================] - 21s 4ms/sample - loss: 0.6743 - accuracy: 0.8106 - binary_accuracy: 0.9976 - recall: 0.7327 - precision: 0.9428 - val_loss: 0.7464 - val_accuracy: 0.8118 - val_binary_accuracy: 0.9977 - val_recall: 0.7513 - val_precision: 0.9373\n",
      "Epoch 15/50\n",
      "5148/5148 [==============================] - 22s 4ms/sample - loss: 0.6330 - accuracy: 0.8202 - binary_accuracy: 0.9976 - recall: 0.7426 - precision: 0.9434 - val_loss: 0.7156 - val_accuracy: 0.8156 - val_binary_accuracy: 0.9978 - val_recall: 0.7647 - val_precision: 0.9400\n",
      "Epoch 16/50\n",
      "5148/5148 [==============================] - 21s 4ms/sample - loss: 0.5929 - accuracy: 0.8297 - binary_accuracy: 0.9977 - recall: 0.7547 - precision: 0.9432 - val_loss: 0.7395 - val_accuracy: 0.8131 - val_binary_accuracy: 0.9977 - val_recall: 0.7662 - val_precision: 0.9297\n",
      "Epoch 17/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.5581 - accuracy: 0.8392 - binary_accuracy: 0.9978 - recall: 0.7678 - precision: 0.9437 - val_loss: 0.7311 - val_accuracy: 0.8162 - val_binary_accuracy: 0.9977 - val_recall: 0.7652 - val_precision: 0.9227\n",
      "Epoch 18/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.5152 - accuracy: 0.8519 - binary_accuracy: 0.9980 - recall: 0.7818 - precision: 0.9469 - val_loss: 0.7240 - val_accuracy: 0.8213 - val_binary_accuracy: 0.9978 - val_recall: 0.7811 - val_precision: 0.9242\n",
      "Epoch 19/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.4669 - accuracy: 0.8666 - binary_accuracy: 0.9981 - recall: 0.7958 - precision: 0.9515 - val_loss: 0.7227 - val_accuracy: 0.8223 - val_binary_accuracy: 0.9977 - val_recall: 0.7831 - val_precision: 0.9143\n",
      "Epoch 20/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.4435 - accuracy: 0.8716 - binary_accuracy: 0.9982 - recall: 0.8061 - precision: 0.9506 - val_loss: 0.7255 - val_accuracy: 0.8195 - val_binary_accuracy: 0.9978 - val_recall: 0.7861 - val_precision: 0.9182\n",
      "Epoch 21/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.3943 - accuracy: 0.8857 - binary_accuracy: 0.9983 - recall: 0.8237 - precision: 0.9570 - val_loss: 0.7132 - val_accuracy: 0.8282 - val_binary_accuracy: 0.9978 - val_recall: 0.7908 - val_precision: 0.9123\n",
      "Epoch 22/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.3514 - accuracy: 0.9003 - binary_accuracy: 0.9985 - recall: 0.8421 - precision: 0.9624 - val_loss: 0.7304 - val_accuracy: 0.8277 - val_binary_accuracy: 0.9978 - val_recall: 0.7906 - val_precision: 0.9176\n",
      "Epoch 23/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.3041 - accuracy: 0.9142 - binary_accuracy: 0.9987 - recall: 0.8613 - precision: 0.9655 - val_loss: 0.7402 - val_accuracy: 0.8246 - val_binary_accuracy: 0.9977 - val_recall: 0.7944 - val_precision: 0.8978\n",
      "Epoch 24/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.2752 - accuracy: 0.9227 - binary_accuracy: 0.9988 - recall: 0.8726 - precision: 0.9677 - val_loss: 0.7295 - val_accuracy: 0.8256 - val_binary_accuracy: 0.9978 - val_recall: 0.8007 - val_precision: 0.9057\n",
      "Epoch 25/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.2439 - accuracy: 0.9338 - binary_accuracy: 0.9989 - recall: 0.8885 - precision: 0.9727 - val_loss: 0.7448 - val_accuracy: 0.8269 - val_binary_accuracy: 0.9977 - val_recall: 0.8014 - val_precision: 0.8990\n",
      "Epoch 26/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.1947 - accuracy: 0.9504 - binary_accuracy: 0.9992 - recall: 0.9129 - precision: 0.9784 - val_loss: 0.7645 - val_accuracy: 0.8303 - val_binary_accuracy: 0.9978 - val_recall: 0.8024 - val_precision: 0.8966\n",
      "Epoch 27/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.1613 - accuracy: 0.9617 - binary_accuracy: 0.9993 - recall: 0.9304 - precision: 0.9827 - val_loss: 0.7787 - val_accuracy: 0.8285 - val_binary_accuracy: 0.9977 - val_recall: 0.8056 - val_precision: 0.8935\n",
      "Epoch 28/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.1292 - accuracy: 0.9728 - binary_accuracy: 0.9995 - recall: 0.9474 - precision: 0.9879 - val_loss: 0.7965 - val_accuracy: 0.8303 - val_binary_accuracy: 0.9977 - val_recall: 0.8107 - val_precision: 0.8840\n",
      "Epoch 29/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.1108 - accuracy: 0.9785 - binary_accuracy: 0.9996 - recall: 0.9572 - precision: 0.9895 - val_loss: 0.8151 - val_accuracy: 0.8295 - val_binary_accuracy: 0.9977 - val_recall: 0.8111 - val_precision: 0.8828\n",
      "Epoch 30/50\n",
      "5148/5148 [==============================] - 19s 4ms/sample - loss: 0.0923 - accuracy: 0.9837 - binary_accuracy: 0.9997 - recall: 0.9672 - precision: 0.9917 - val_loss: 0.8279 - val_accuracy: 0.8318 - val_binary_accuracy: 0.9977 - val_recall: 0.8146 - val_precision: 0.8834\n",
      "Epoch 31/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0725 - accuracy: 0.9894 - binary_accuracy: 0.9998 - recall: 0.9787 - precision: 0.9945 - val_loss: 0.8336 - val_accuracy: 0.8295 - val_binary_accuracy: 0.9977 - val_recall: 0.8114 - val_precision: 0.8810\n",
      "Epoch 32/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0530 - accuracy: 0.9945 - binary_accuracy: 0.9999 - recall: 0.9888 - precision: 0.9970 - val_loss: 0.8452 - val_accuracy: 0.8323 - val_binary_accuracy: 0.9977 - val_recall: 0.8170 - val_precision: 0.8803\n",
      "Epoch 33/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0401 - accuracy: 0.9971 - binary_accuracy: 0.9999 - recall: 0.9942 - precision: 0.9983 - val_loss: 0.8567 - val_accuracy: 0.8328 - val_binary_accuracy: 0.9977 - val_recall: 0.8159 - val_precision: 0.8761\n",
      "Epoch 34/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0316 - accuracy: 0.9983 - binary_accuracy: 1.0000 - recall: 0.9970 - precision: 0.9988 - val_loss: 0.8687 - val_accuracy: 0.8318 - val_binary_accuracy: 0.9977 - val_recall: 0.8163 - val_precision: 0.8761\n",
      "Epoch 35/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0247 - accuracy: 0.9988 - binary_accuracy: 1.0000 - recall: 0.9983 - precision: 0.9991 - val_loss: 0.9035 - val_accuracy: 0.8308 - val_binary_accuracy: 0.9976 - val_recall: 0.8194 - val_precision: 0.8702\n",
      "Epoch 36/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0192 - accuracy: 0.9992 - binary_accuracy: 1.0000 - recall: 0.9990 - precision: 0.9994 - val_loss: 0.9033 - val_accuracy: 0.8336 - val_binary_accuracy: 0.9977 - val_recall: 0.8191 - val_precision: 0.8697\n",
      "Epoch 37/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0160 - accuracy: 0.9992 - binary_accuracy: 1.0000 - recall: 0.9991 - precision: 0.9993 - val_loss: 0.9073 - val_accuracy: 0.8326 - val_binary_accuracy: 0.9976 - val_recall: 0.8203 - val_precision: 0.8702\n",
      "Epoch 38/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0129 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9992 - precision: 0.9995 - val_loss: 0.9265 - val_accuracy: 0.8310 - val_binary_accuracy: 0.9976 - val_recall: 0.8193 - val_precision: 0.8695\n",
      "Epoch 39/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0122 - accuracy: 0.9992 - binary_accuracy: 1.0000 - recall: 0.9991 - precision: 0.9993 - val_loss: 0.9375 - val_accuracy: 0.8313 - val_binary_accuracy: 0.9976 - val_recall: 0.8209 - val_precision: 0.8665\n",
      "Epoch 40/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0132 - accuracy: 0.9990 - binary_accuracy: 1.0000 - recall: 0.9989 - precision: 0.9992 - val_loss: 0.9499 - val_accuracy: 0.8323 - val_binary_accuracy: 0.9976 - val_recall: 0.8205 - val_precision: 0.8628\n",
      "Epoch 41/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0113 - accuracy: 0.9993 - binary_accuracy: 1.0000 - recall: 0.9991 - precision: 0.9994 - val_loss: 0.9591 - val_accuracy: 0.8318 - val_binary_accuracy: 0.9976 - val_recall: 0.8189 - val_precision: 0.8596\n",
      "Epoch 42/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0096 - accuracy: 0.9994 - binary_accuracy: 1.0000 - recall: 0.9994 - precision: 0.9995 - val_loss: 0.9609 - val_accuracy: 0.8336 - val_binary_accuracy: 0.9976 - val_recall: 0.8250 - val_precision: 0.8690\n",
      "Epoch 43/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0088 - accuracy: 0.9993 - binary_accuracy: 1.0000 - recall: 0.9992 - precision: 0.9994 - val_loss: 0.9586 - val_accuracy: 0.8331 - val_binary_accuracy: 0.9976 - val_recall: 0.8222 - val_precision: 0.8665\n",
      "Epoch 44/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0097 - accuracy: 0.9992 - binary_accuracy: 1.0000 - recall: 0.9991 - precision: 0.9993 - val_loss: 0.9934 - val_accuracy: 0.8328 - val_binary_accuracy: 0.9976 - val_recall: 0.8220 - val_precision: 0.8655\n",
      "Epoch 45/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0137 - accuracy: 0.9986 - binary_accuracy: 1.0000 - recall: 0.9983 - precision: 0.9987 - val_loss: 0.9831 - val_accuracy: 0.8292 - val_binary_accuracy: 0.9976 - val_recall: 0.8212 - val_precision: 0.8606\n",
      "Epoch 46/50\n",
      "5148/5148 [==============================] - 19s 4ms/sample - loss: 0.0363 - accuracy: 0.9929 - binary_accuracy: 0.9999 - recall: 0.9904 - precision: 0.9947 - val_loss: 1.0000 - val_accuracy: 0.8254 - val_binary_accuracy: 0.9975 - val_recall: 0.8118 - val_precision: 0.8623\n",
      "Epoch 47/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0975 - accuracy: 0.9727 - binary_accuracy: 0.9996 - recall: 0.9628 - precision: 0.9811 - val_loss: 0.9124 - val_accuracy: 0.8254 - val_binary_accuracy: 0.9976 - val_recall: 0.8123 - val_precision: 0.8691\n",
      "Epoch 48/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0863 - accuracy: 0.9783 - binary_accuracy: 0.9996 - recall: 0.9685 - precision: 0.9853 - val_loss: 0.9143 - val_accuracy: 0.8236 - val_binary_accuracy: 0.9976 - val_recall: 0.8127 - val_precision: 0.8701\n",
      "Epoch 49/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0453 - accuracy: 0.9915 - binary_accuracy: 0.9999 - recall: 0.9879 - precision: 0.9939 - val_loss: 0.9098 - val_accuracy: 0.8331 - val_binary_accuracy: 0.9977 - val_recall: 0.8224 - val_precision: 0.8716\n",
      "Epoch 50/50\n",
      "5148/5148 [==============================] - 20s 4ms/sample - loss: 0.0188 - accuracy: 0.9982 - binary_accuracy: 1.0000 - recall: 0.9976 - precision: 0.9986 - val_loss: 0.9267 - val_accuracy: 0.8372 - val_binary_accuracy: 0.9977 - val_recall: 0.8252 - val_precision: 0.8727\n"
     ]
    }
   ],
   "source": [
    "new_experiment.run_experiment(train_token_ids_array, one_hot_mesh_shifted_train, one_hot_mesh_train, \n",
    "                              val_token_ids_array, one_hot_mesh_shifted_val, one_hot_mesh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5148 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "5148/5148 [==============================] - 8s 2ms/step - loss: 2.5586 - acc: 0.5653 - binary_accuracy: 0.9943 - recall: 0.4254 - precision: 0.6532 - val_loss: 1.7772 - val_acc: 0.6921 - val_binary_accuracy: 0.9956 - val_recall: 0.5446 - val_precision: 0.8309\n",
      "Epoch 2/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 1.9180 - acc: 0.6210 - binary_accuracy: 0.9955 - recall: 0.5235 - precision: 0.8424 - val_loss: 1.5358 - val_acc: 0.6915 - val_binary_accuracy: 0.9966 - val_recall: 0.5628 - val_precision: 0.9959\n",
      "Epoch 3/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 1.7078 - acc: 0.6320 - binary_accuracy: 0.9961 - recall: 0.5258 - precision: 0.9584 - val_loss: 1.3822 - val_acc: 0.7018 - val_binary_accuracy: 0.9967 - val_recall: 0.5808 - val_precision: 0.9882\n",
      "Epoch 4/50\n",
      "5148/5148 [==============================] - 7s 1ms/step - loss: 1.5519 - acc: 0.6579 - binary_accuracy: 0.9964 - recall: 0.5574 - precision: 0.9701 - val_loss: 1.2411 - val_acc: 0.7277 - val_binary_accuracy: 0.9970 - val_recall: 0.6351 - val_precision: 0.9728\n",
      "Epoch 5/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 1.3851 - acc: 0.6882 - binary_accuracy: 0.9966 - recall: 0.5797 - precision: 0.9677 - val_loss: 1.1245 - val_acc: 0.7492 - val_binary_accuracy: 0.9971 - val_recall: 0.6433 - val_precision: 0.9868\n",
      "Epoch 6/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 1.2437 - acc: 0.7080 - binary_accuracy: 0.9967 - recall: 0.6002 - precision: 0.9687 - val_loss: 1.0287 - val_acc: 0.7615 - val_binary_accuracy: 0.9972 - val_recall: 0.6605 - val_precision: 0.9773\n",
      "Epoch 7/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 1.1428 - acc: 0.7264 - binary_accuracy: 0.9968 - recall: 0.6170 - precision: 0.9636 - val_loss: 0.9876 - val_acc: 0.7703 - val_binary_accuracy: 0.9973 - val_recall: 0.6672 - val_precision: 0.9746\n",
      "Epoch 8/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 1.0740 - acc: 0.7370 - binary_accuracy: 0.9969 - recall: 0.6326 - precision: 0.9559 - val_loss: 0.9261 - val_acc: 0.7782 - val_binary_accuracy: 0.9973 - val_recall: 0.6851 - val_precision: 0.9591\n",
      "Epoch 9/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 1.0216 - acc: 0.7427 - binary_accuracy: 0.9970 - recall: 0.6470 - precision: 0.9507 - val_loss: 0.8937 - val_acc: 0.7854 - val_binary_accuracy: 0.9973 - val_recall: 0.6903 - val_precision: 0.9587\n",
      "Epoch 10/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.9751 - acc: 0.7507 - binary_accuracy: 0.9971 - recall: 0.6679 - precision: 0.9461 - val_loss: 0.8675 - val_acc: 0.7826 - val_binary_accuracy: 0.9975 - val_recall: 0.7290 - val_precision: 0.9336\n",
      "Epoch 11/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.9462 - acc: 0.7542 - binary_accuracy: 0.9972 - recall: 0.6785 - precision: 0.9434 - val_loss: 0.8909 - val_acc: 0.7772 - val_binary_accuracy: 0.9974 - val_recall: 0.7321 - val_precision: 0.9144\n",
      "Epoch 12/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.9154 - acc: 0.7591 - binary_accuracy: 0.9972 - recall: 0.6836 - precision: 0.9411 - val_loss: 0.8509 - val_acc: 0.7900 - val_binary_accuracy: 0.9975 - val_recall: 0.7356 - val_precision: 0.9234\n",
      "Epoch 13/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.8796 - acc: 0.7658 - binary_accuracy: 0.9972 - recall: 0.6892 - precision: 0.9418 - val_loss: 0.8413 - val_acc: 0.7854 - val_binary_accuracy: 0.9975 - val_recall: 0.7221 - val_precision: 0.9524\n",
      "Epoch 14/50\n",
      "5148/5148 [==============================] - 7s 1ms/step - loss: 0.8557 - acc: 0.7692 - binary_accuracy: 0.9973 - recall: 0.6946 - precision: 0.9426 - val_loss: 0.8178 - val_acc: 0.7915 - val_binary_accuracy: 0.9976 - val_recall: 0.7318 - val_precision: 0.9456\n",
      "Epoch 15/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.8374 - acc: 0.7732 - binary_accuracy: 0.9973 - recall: 0.6991 - precision: 0.9414 - val_loss: 0.8162 - val_acc: 0.7908 - val_binary_accuracy: 0.9976 - val_recall: 0.7300 - val_precision: 0.9471\n",
      "Epoch 16/50\n",
      "5148/5148 [==============================] - 7s 1ms/step - loss: 0.8164 - acc: 0.7764 - binary_accuracy: 0.9973 - recall: 0.7025 - precision: 0.9415 - val_loss: 0.8052 - val_acc: 0.7923 - val_binary_accuracy: 0.9976 - val_recall: 0.7354 - val_precision: 0.9467\n",
      "Epoch 17/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.7913 - acc: 0.7818 - binary_accuracy: 0.9974 - recall: 0.7084 - precision: 0.9430 - val_loss: 0.7898 - val_acc: 0.7962 - val_binary_accuracy: 0.9976 - val_recall: 0.7408 - val_precision: 0.9411\n",
      "Epoch 18/50\n",
      "5148/5148 [==============================] - 7s 1ms/step - loss: 0.7706 - acc: 0.7871 - binary_accuracy: 0.9974 - recall: 0.7122 - precision: 0.9435 - val_loss: 0.7919 - val_acc: 0.7941 - val_binary_accuracy: 0.9976 - val_recall: 0.7413 - val_precision: 0.9424\n",
      "Epoch 19/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.7444 - acc: 0.7927 - binary_accuracy: 0.9975 - recall: 0.7192 - precision: 0.9442 - val_loss: 0.7685 - val_acc: 0.7995 - val_binary_accuracy: 0.9977 - val_recall: 0.7477 - val_precision: 0.9395\n",
      "Epoch 20/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.7173 - acc: 0.7998 - binary_accuracy: 0.9975 - recall: 0.7244 - precision: 0.9458 - val_loss: 0.7779 - val_acc: 0.7997 - val_binary_accuracy: 0.9976 - val_recall: 0.7508 - val_precision: 0.9333\n",
      "Epoch 21/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.6879 - acc: 0.8081 - binary_accuracy: 0.9976 - recall: 0.7311 - precision: 0.9474 - val_loss: 0.7695 - val_acc: 0.8036 - val_binary_accuracy: 0.9976 - val_recall: 0.7592 - val_precision: 0.9217\n",
      "Epoch 22/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.6606 - acc: 0.8162 - binary_accuracy: 0.9977 - recall: 0.7387 - precision: 0.9495 - val_loss: 0.7616 - val_acc: 0.8074 - val_binary_accuracy: 0.9977 - val_recall: 0.7521 - val_precision: 0.9368\n",
      "Epoch 23/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.6250 - acc: 0.8267 - binary_accuracy: 0.9978 - recall: 0.7491 - precision: 0.9528 - val_loss: 0.7430 - val_acc: 0.8064 - val_binary_accuracy: 0.9977 - val_recall: 0.7618 - val_precision: 0.9375\n",
      "Epoch 24/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.5932 - acc: 0.8357 - binary_accuracy: 0.9978 - recall: 0.7583 - precision: 0.9544 - val_loss: 0.7320 - val_acc: 0.8126 - val_binary_accuracy: 0.9977 - val_recall: 0.7638 - val_precision: 0.9338\n",
      "Epoch 25/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.5519 - acc: 0.8464 - binary_accuracy: 0.9979 - recall: 0.7696 - precision: 0.9588 - val_loss: 0.7269 - val_acc: 0.8185 - val_binary_accuracy: 0.9978 - val_recall: 0.7654 - val_precision: 0.9392\n",
      "Epoch 26/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.5207 - acc: 0.8559 - binary_accuracy: 0.9980 - recall: 0.7789 - precision: 0.9597 - val_loss: 0.7185 - val_acc: 0.8203 - val_binary_accuracy: 0.9977 - val_recall: 0.7754 - val_precision: 0.9222\n",
      "Epoch 27/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.4834 - acc: 0.8670 - binary_accuracy: 0.9981 - recall: 0.7929 - precision: 0.9625 - val_loss: 0.7022 - val_acc: 0.8262 - val_binary_accuracy: 0.9978 - val_recall: 0.7785 - val_precision: 0.9253\n",
      "Epoch 28/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.4399 - acc: 0.8808 - binary_accuracy: 0.9983 - recall: 0.8097 - precision: 0.9657 - val_loss: 0.6962 - val_acc: 0.8251 - val_binary_accuracy: 0.9978 - val_recall: 0.7800 - val_precision: 0.9291\n",
      "Epoch 29/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.4059 - acc: 0.8903 - binary_accuracy: 0.9984 - recall: 0.8228 - precision: 0.9678 - val_loss: 0.6926 - val_acc: 0.8282 - val_binary_accuracy: 0.9978 - val_recall: 0.7856 - val_precision: 0.9176\n",
      "Epoch 30/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.3745 - acc: 0.8987 - binary_accuracy: 0.9985 - recall: 0.8363 - precision: 0.9685 - val_loss: 0.6858 - val_acc: 0.8379 - val_binary_accuracy: 0.9978 - val_recall: 0.7959 - val_precision: 0.9178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.3486 - acc: 0.9064 - binary_accuracy: 0.9986 - recall: 0.8458 - precision: 0.9704 - val_loss: 0.6973 - val_acc: 0.8323 - val_binary_accuracy: 0.9978 - val_recall: 0.7941 - val_precision: 0.9168\n",
      "Epoch 32/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.3198 - acc: 0.9153 - binary_accuracy: 0.9987 - recall: 0.8604 - precision: 0.9721 - val_loss: 0.6936 - val_acc: 0.8362 - val_binary_accuracy: 0.9979 - val_recall: 0.7992 - val_precision: 0.9165\n",
      "Epoch 33/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.2904 - acc: 0.9249 - binary_accuracy: 0.9988 - recall: 0.8731 - precision: 0.9755 - val_loss: 0.6939 - val_acc: 0.8372 - val_binary_accuracy: 0.9978 - val_recall: 0.8023 - val_precision: 0.9082\n",
      "Epoch 34/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.3115 - acc: 0.9186 - binary_accuracy: 0.9987 - recall: 0.8673 - precision: 0.9684 - val_loss: 0.7553 - val_acc: 0.8267 - val_binary_accuracy: 0.9977 - val_recall: 0.7882 - val_precision: 0.9086\n",
      "Epoch 35/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.3438 - acc: 0.9041 - binary_accuracy: 0.9986 - recall: 0.8487 - precision: 0.9630 - val_loss: 0.6905 - val_acc: 0.8379 - val_binary_accuracy: 0.9979 - val_recall: 0.8051 - val_precision: 0.9123\n",
      "Epoch 36/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.2548 - acc: 0.9350 - binary_accuracy: 0.9990 - recall: 0.8901 - precision: 0.9763 - val_loss: 0.6835 - val_acc: 0.8436 - val_binary_accuracy: 0.9979 - val_recall: 0.8090 - val_precision: 0.9097\n",
      "Epoch 37/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.2201 - acc: 0.9463 - binary_accuracy: 0.9991 - recall: 0.9077 - precision: 0.9808 - val_loss: 0.6868 - val_acc: 0.8469 - val_binary_accuracy: 0.9979 - val_recall: 0.8131 - val_precision: 0.9101\n",
      "Epoch 38/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.1934 - acc: 0.9542 - binary_accuracy: 0.9993 - recall: 0.9202 - precision: 0.9830 - val_loss: 0.6934 - val_acc: 0.8444 - val_binary_accuracy: 0.9979 - val_recall: 0.8200 - val_precision: 0.9016\n",
      "Epoch 39/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.1720 - acc: 0.9606 - binary_accuracy: 0.9994 - recall: 0.9306 - precision: 0.9857 - val_loss: 0.7120 - val_acc: 0.8426 - val_binary_accuracy: 0.9979 - val_recall: 0.8169 - val_precision: 0.9038\n",
      "Epoch 40/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.1550 - acc: 0.9658 - binary_accuracy: 0.9994 - recall: 0.9392 - precision: 0.9871 - val_loss: 0.7038 - val_acc: 0.8490 - val_binary_accuracy: 0.9979 - val_recall: 0.8218 - val_precision: 0.9020\n",
      "Epoch 41/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.1424 - acc: 0.9689 - binary_accuracy: 0.9995 - recall: 0.9441 - precision: 0.9878 - val_loss: 0.7151 - val_acc: 0.8395 - val_binary_accuracy: 0.9978 - val_recall: 0.8156 - val_precision: 0.8948\n",
      "Epoch 42/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.1314 - acc: 0.9723 - binary_accuracy: 0.9995 - recall: 0.9506 - precision: 0.9889 - val_loss: 0.7215 - val_acc: 0.8492 - val_binary_accuracy: 0.9979 - val_recall: 0.8274 - val_precision: 0.8974\n",
      "Epoch 43/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.1145 - acc: 0.9774 - binary_accuracy: 0.9996 - recall: 0.9582 - precision: 0.9909 - val_loss: 0.7370 - val_acc: 0.8479 - val_binary_accuracy: 0.9978 - val_recall: 0.8251 - val_precision: 0.8894\n",
      "Epoch 44/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.1031 - acc: 0.9797 - binary_accuracy: 0.9997 - recall: 0.9639 - precision: 0.9916 - val_loss: 0.7295 - val_acc: 0.8485 - val_binary_accuracy: 0.9979 - val_recall: 0.8277 - val_precision: 0.8934\n",
      "Epoch 45/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.0894 - acc: 0.9836 - binary_accuracy: 0.9997 - recall: 0.9702 - precision: 0.9935 - val_loss: 0.7409 - val_acc: 0.8513 - val_binary_accuracy: 0.9979 - val_recall: 0.8333 - val_precision: 0.8943\n",
      "Epoch 46/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.0853 - acc: 0.9843 - binary_accuracy: 0.9997 - recall: 0.9719 - precision: 0.9933 - val_loss: 0.7542 - val_acc: 0.8505 - val_binary_accuracy: 0.9979 - val_recall: 0.8290 - val_precision: 0.8908\n",
      "Epoch 47/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.0766 - acc: 0.9870 - binary_accuracy: 0.9998 - recall: 0.9762 - precision: 0.9944 - val_loss: 0.7560 - val_acc: 0.8485 - val_binary_accuracy: 0.9979 - val_recall: 0.8321 - val_precision: 0.8909\n",
      "Epoch 48/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.0674 - acc: 0.9889 - binary_accuracy: 0.9998 - recall: 0.9797 - precision: 0.9951 - val_loss: 0.7729 - val_acc: 0.8500 - val_binary_accuracy: 0.9979 - val_recall: 0.8331 - val_precision: 0.8874\n",
      "Epoch 49/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.0591 - acc: 0.9911 - binary_accuracy: 0.9998 - recall: 0.9831 - precision: 0.9959 - val_loss: 0.7664 - val_acc: 0.8505 - val_binary_accuracy: 0.9979 - val_recall: 0.8349 - val_precision: 0.8836\n",
      "Epoch 50/50\n",
      "5148/5148 [==============================] - 6s 1ms/step - loss: 0.0564 - acc: 0.9916 - binary_accuracy: 0.9998 - recall: 0.9838 - precision: 0.9958 - val_loss: 0.7751 - val_acc: 0.8490 - val_binary_accuracy: 0.9979 - val_recall: 0.8318 - val_precision: 0.8890\n"
     ]
    }
   ],
   "source": [
    "new_experiment.run_experiment(one_hot_reports_train, one_hot_mesh_shifted_train, one_hot_mesh_train, \n",
    "                              one_hot_reports_val, one_hot_mesh_shifted_val, one_hot_mesh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_experiment.save_weights_history(model_output_dir+'emb_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of specific experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = dir + 'trained_models/seq2seq/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "hidden_dim = 512\n",
    "\n",
    "param_fn = 'emb_param_seq2seq_epochs_{}_hiddendim_{}.pkl'\\\n",
    ".format(epochs, hidden_dim)\n",
    "params = pickle.load(open(model_output_dir + param_fn, 'rb'))\n",
    "\n",
    "old_experiment = Seq2Seq(**params)\n",
    "old_experiment.build_model()\n",
    "old_experiment.load_weights_history(model_output_dir+'emb_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_start_end(seq, start_token='start', end_token='end'):\n",
    "    stripped_seq = []\n",
    "    for s in seq:\n",
    "        if s not in [start_token, end_token]:\n",
    "            stripped_seq.append(s)\n",
    "    return stripped_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original report:  ['airspace', 'opacity', 'left', 'upper', 'lung', '.', 'heart', 'size', 'within', 'normal', 'limits', '.', 'mild', 'calcification', 'aortic', '.', 'airspace', 'opacity', 'left', 'upper', 'lung', 'may', 'represent', 'streaky', 'atelectasis', 'resolving', 'pneumonia']\n",
      "True mesh caption:  ['opacity', 'lung', 'upper_lobe', 'left']\n",
      "Predicted mesh caption:  ['atherosclerosis', 'aorta', 'opacity', 'lung', 'upper_lobe', 'right', 'opacity', 'lung', 'upper_lobe', 'right']\n",
      "\n",
      "Original report:  ['heart', 'size', 'within', 'normal', 'limits', '.', 'calcified', 'right', 'hilar', 'lymph', 'noted']\n",
      "True mesh caption:  ['calcinosis', 'lung', 'hilum', 'lymph_nodes', 'right']\n",
      "Predicted mesh caption:  ['calcinosis', 'lung', 'hilum', 'lymph_nodes', 'right']\n",
      "\n",
      "Original report:  ['low', 'lung', 'volumes', 'noted', '.', 'allowing', 'technical', 'factors', 'heart', 'size', 'normal', '.', 'mediastinum', 'unremarkable', '.', 'increased', 'bilateral', 'predominantly', 'perihilar', 'interstitial', 'opacity', ',', 'consistent', 'pulmonary', 'edema', '.', 'unremarkable', '.', 'increased', 'bilateral', 'interstitial', 'opacity', ',', 'consistent', 'mild']\n",
      "True mesh caption:  ['opacity', 'lung', 'hilum', 'bilateral', 'interstitial']\n",
      "Predicted mesh caption:  ['lung', 'hypoinflation', 'markings', 'lung', 'interstitial', 'opacity', 'lung', 'bilateral', 'focal', 'pleural_effusion']\n",
      "\n",
      "Original report:  ['heart', 'size', 'normal', '.', 'lungs', 'clear', '.', 'hilar', 'mediastinal', 'contours', 'normal', '.', 'normal', 'pulmonary', 'vascularity', '.', 'piercing']\n",
      "True mesh caption:  ['foreign_bodies', 'abdomen']\n",
      "Predicted mesh caption:  ['normal']\n",
      "\n",
      "Original report:  ['lungs', 'clear', 'bilaterally', '.', 'cardio', 'mediastinal', 'silhouette', 'unremarkable', '.', 'stable', 'foreign', 'body', 'left', 'breast', 'nipple', 'piercing', '.', 'visualized', 'osseous', 'structures', 'thorax', 'without', 'acute', 'abnormality']\n",
      "True mesh caption:  ['foreign_bodies', 'breast', 'left']\n",
      "Predicted mesh caption:  ['foreign_bodies', 'thorax', 'left']\n",
      "\n",
      "Original report:  ['normal', 'heart', 'size', '.', 'stable', 'tortuous', 'aorta', '.', 'prior', 'granulomatous', 'disease', '.', 'unchanged', 'exam', 'without', 'acute', 'abnormality']\n",
      "True mesh caption:  ['aorta', 'tortuous']\n",
      "Predicted mesh caption:  ['aorta', 'tortuous', 'scoliosis', 'spine']\n",
      "\n",
      "Original report:  ['heart', 'size', 'normal', '.', 'lungs', 'clear', '.', 'tortuous', 'aorta', '.', 'prominent', 'first', 'ribs']\n",
      "True mesh caption:  ['aorta', 'tortuous']\n",
      "Predicted mesh caption:  ['aorta', 'tortuous', 'cardiomegaly']\n",
      "\n",
      "Original report:  ['sternotomy', 'mediastinal', 'surgical', 'clips', 'remain', '.', 'cardiomediastinal', 'silhouette', 'stable', 'appearance', '.', 'thoracic', 'aorta', 'tortuous', 'calcified', 'stable', 'appearance', 'since', 'exam', '.', 'scattered', 'right', 'basilar', 'subsegmental', 'atelectasis', '.', 'left', 'lung', 'appears', 'clear', '.', 'moderate', 'degenerative', 'changes', 'thoracic']\n",
      "True mesh caption:  ['pulmonary_atelectasis', 'base', 'right', 'scattered', 'mild']\n",
      "Predicted mesh caption:  ['aorta_thoracic', 'tortuous', 'atherosclerosis', 'aorta_thoracic', 'calcified_granuloma', 'thorax', 'humerus', 'left', 'deformity', 'humerus', 'left']\n",
      "\n",
      "Original report:  ['normal', 'cardiomediastinal', 'silhouette', '.', 'mild', 'degenerative', 'changes', 'spine']\n",
      "True mesh caption:  ['spine', 'degenerative', 'mild']\n",
      "Predicted mesh caption:  ['spine', 'degenerative', 'mild']\n",
      "\n",
      "Original report:  ['sequelae', 'old', 'granulomatous', 'disease', 'noted', '.', 'lungs', 'clear', 'without', 'focal', 'air', 'space', 'disease', '.', 'heart', 'mediastinum', 'normal', 'size', 'contour', '.', 'degenerative', 'changes', 'spine', '.', 'clear', 'lungs']\n",
      "True mesh caption:  ['spine', 'degenerative']\n",
      "Predicted mesh caption:  ['granulomatous_disease', 'thoracic_vertebrae', 'degenerative']\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    sample = val_df.sample(1)\n",
    "    true_mesh_caption = list(sample.single_mesh)[0]\n",
    "    sample_report = list(sample.pad_text_report)[0]\n",
    "    \n",
    "    sample_report_ids = []\n",
    "    for token in sample_report:\n",
    "        if token in word_to_id.keys():\n",
    "            sample_report_ids.append(word_to_id[token])\n",
    "        else:\n",
    "            sample_report_ids.append(word_to_id[unknown_token])\n",
    "    \n",
    "    sample_report_ids = np.array(sample_report_ids).reshape(1, len(sample_report_ids))\n",
    "    #one_hot_sample_report = dpt.one_hot_sequence(sample_report_ids, report_vocab_length)\n",
    "    \n",
    "    #target = predict_sequence(infenc, infdec, one_hot_sample_report, n_steps_out, n_features_out)\n",
    "    #target = old_experiment.predict_sequence(one_hot_sample_report)\n",
    "    target = old_experiment.predict_sequence(sample_report_ids)\n",
    "    predicted_mesh_ids = one_hot_decode(target)\n",
    "    predicted_mesh = [id_to_mesh[idx] for idx in predicted_mesh_ids]\n",
    "    \n",
    "    sample_report = strip_start_end(sample_report)\n",
    "    predicted_mesh = strip_start_end(predicted_mesh)\n",
    "    \n",
    "    print('')\n",
    "    print('Original report: ', sample_report)\n",
    "    print('True mesh caption: ', true_mesh_caption)\n",
    "    print('Predicted mesh caption: ', predicted_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate BLEU scores on all trian/val/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def evaluate_model(model, df, report_vocab_length):\n",
    "    actual, predicted = list(), list()\n",
    "    bleu1, bleu2, bleu3, bleu4 = list(), list(), list(), list()\n",
    "\n",
    "    for _, sample in df.iterrows():\n",
    "        true_mesh_caption = sample.single_mesh\n",
    "        sample_report = sample.pad_text_report\n",
    "\n",
    "        sample_report_ids = []\n",
    "        for token in sample_report:\n",
    "            if token in word_to_id.keys():\n",
    "                sample_report_ids.append(word_to_id[token])\n",
    "            else:\n",
    "                sample_report_ids.append(word_to_id[unknown_token])\n",
    "\n",
    "        sample_report_ids = np.array(sample_report_ids).reshape(1, len(sample_report_ids))\n",
    "        #one_hot_sample_report = dpt.one_hot_sequence(sample_report_ids, report_vocab_length)\n",
    "\n",
    "        #target = predict_sequence(infenc, infdec, one_hot_sample_report, n_steps_out, n_features_out)\n",
    "        #target = model.predict_sequence(one_hot_sample_report)\n",
    "        target = model.predict_sequence(sample_report_ids)\n",
    "        predicted_mesh_ids = one_hot_decode(target)\n",
    "        predicted_mesh = [id_to_mesh[idx] for idx in predicted_mesh_ids]\n",
    "\n",
    "        # sample_report = strip_start_end(sample_report)\n",
    "        yhat = strip_start_end(predicted_mesh)\n",
    "        reference = true_mesh_caption\n",
    "        \n",
    "        # calculate BLEU score\n",
    "        bleu1.append(sentence_bleu([reference], yhat, weights=(1.0, 0, 0, 0)))\n",
    "        bleu2.append(sentence_bleu([reference], yhat, weights=(0.5, 0.5, 0, 0)))\n",
    "        bleu3.append(sentence_bleu([reference], yhat, weights=(0.3, 0.3, 0.3, 0)))\n",
    "        bleu4.append(sentence_bleu([reference], yhat, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "    \n",
    "        # store actual and predicted\n",
    "        actual.append(reference)\n",
    "        predicted.append(yhat)\n",
    "        \n",
    "    print('BLEU1: ', np.mean(bleu1)*100)\n",
    "    print('BLEU2: ', np.mean(bleu2)*100)\n",
    "    print('BLEU3: ', np.mean(bleu3)*100)\n",
    "    print('BLEU4: ', np.mean(bleu4)*100)\n",
    "    \n",
    "    return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/medic02/users/ag6516/python3env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/vol/medic02/users/ag6516/python3env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/vol/medic02/users/ag6516/python3env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU1:  71.41680682785245\n",
      "BLEU2:  44.64865037160584\n",
      "BLEU3:  31.979927161300047\n",
      "BLEU4:  17.600822157542577\n"
     ]
    }
   ],
   "source": [
    "train_actual, train_predicted = evaluate_model(old_experiment, train_df, report_vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU1:  69.22569916540729\n",
      "BLEU2:  41.01887071533283\n",
      "BLEU3:  28.331983321743117\n",
      "BLEU4:  15.250252448376528\n"
     ]
    }
   ],
   "source": [
    "train_actual, train_predicted = evaluate_model(old_experiment, train_df, report_vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU1:  60.06780874781047\n",
      "BLEU2:  19.520045826637116\n",
      "BLEU3:  10.345706465515486\n",
      "BLEU4:  4.569959657318097\n"
     ]
    }
   ],
   "source": [
    "val_actual, val_predicted = evaluate_model(old_experiment, val_df, report_vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/medic02/users/ag6516/python3env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/vol/medic02/users/ag6516/python3env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/vol/medic02/users/ag6516/python3env/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU1:  61.21837222560159\n",
      "BLEU2:  19.801445506807212\n",
      "BLEU3:  10.961680790378018\n",
      "BLEU4:  3.9947152852943764\n"
     ]
    }
   ],
   "source": [
    "val_actual, val_predicted = evaluate_model(old_experiment, val_df, report_vocab_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate ROUGE scores on all train/val/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rouge\n",
    "\n",
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
    "                       max_n=4,\n",
    "                       limit_length=True,\n",
    "                       length_limit=100,\n",
    "                       length_limit_type='words',\n",
    "                       apply_avg='Avg',\n",
    "                       apply_best='Best',\n",
    "                       alpha=0.5, # Default F1_score\n",
    "                       weight_factor=1.2,\n",
    "                       stemming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_results(p, r, f):\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-1:\tP: 69.24\tR: 93.56\tF1: 76.22\n",
      "\trouge-2:\tP: 41.10\tR: 67.14\tF1: 47.69\n",
      "\trouge-3:\tP: 29.48\tR: 54.22\tF1: 34.92\n",
      "\trouge-4:\tP: 18.27\tR: 39.25\tF1: 22.28\n",
      "\trouge-l:\tP: 72.17\tR: 93.74\tF1: 79.02\n",
      "\trouge-w:\tP: 68.90\tR: 76.60\tF1: 70.04\n"
     ]
    }
   ],
   "source": [
    "train_hypotheses = [' '.join(p) for p in train_predicted]\n",
    "train_references = [' '.join(a) for a in train_actual]\n",
    "\n",
    "scores = evaluator.get_scores(train_hypotheses, train_references)\n",
    "\n",
    "for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "    print(prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-1:\tP: 62.76\tR: 75.75\tF1: 66.47\n",
      "\trouge-2:\tP: 21.96\tR: 32.11\tF1: 24.45\n",
      "\trouge-3:\tP: 12.68\tR: 20.02\tF1: 14.62\n",
      "\trouge-4:\tP:  6.89\tR: 11.69\tF1:  7.96\n",
      "\trouge-l:\tP: 65.17\tR: 76.90\tF1: 68.87\n",
      "\trouge-w:\tP: 62.21\tR: 65.42\tF1: 62.24\n"
     ]
    }
   ],
   "source": [
    "val_hypotheses = [' '.join(p) for p in val_predicted]\n",
    "val_references = [' '.join(a) for a in val_actual]\n",
    "\n",
    "scores = evaluator.get_scores(val_hypotheses, val_references)\n",
    "\n",
    "for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "    print(prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
